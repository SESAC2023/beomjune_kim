{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBZFZM3Sh4Sp",
        "outputId": "fa42cfe4-b932-41d1-ae72-f0018d834307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.2\n",
            "Collecting soynlp\n",
            "  Downloading soynlp-0.0.493-py3-none-any.whl (416 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.8/416.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.10/dist-packages (from soynlp) (1.23.5)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.10/dist-packages (from soynlp) (5.9.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from soynlp) (1.11.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from soynlp) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->soynlp) (3.2.0)\n",
            "Installing collected packages: soynlp\n",
            "Successfully installed soynlp-0.0.493\n"
          ]
        }
      ],
      "source": [
        "# HuggingFace랑 연동되어 한국어 모델을 포함해 다양한 큰 규모의(large-scale) 트랜스포머 모델(BERT, ELECTRA 등)을 제공한다.\n",
        "!pip install transformers\n",
        "# 직접 사전(dictionary)를 직접 정의하지 않고도, 한국어가 가지는 특수한 단어를 포함하여 토큰으로 만들 수 있도록 도와준다.\n",
        "!pip install soynlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s6NEGtu8bDsB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cb8fiB99Eq30"
      },
      "outputs": [],
      "source": [
        "\n",
        "# PyTorch 라이브러리 불러오기\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# 사전 학습된 트랜스포머(Transformer) 모델 사용하기\n",
        "from transformers import (\n",
        "    # HuggingFace에 있는 ELECTRA 모델과 연동된 4가지 라이브러리\n",
        "    # 왜 BERT가 있는데 굳이 ELECTRA를 가져와야 할까요?\n",
        "    # 이전에 했던 BigBird는 사실상 BERT와 유사한데\n",
        "    # ELECTRA는 생성자(Generator)가 따로 존재하는 구조로 다르기 때문에 다른 아키텍처\n",
        "    ElectraPreTrainedModel, # 대규모 데이터로 사전 학습된 모델\n",
        "    ElectraModel,\n",
        "    ElectraConfig,\n",
        "    ElectraTokenizer, # 한국어 문장에서 자주 등장하는 \"토큰\"에 대해서 vocabulary 정의\n",
        "    BertPreTrainedModel,\n",
        "    BertModel,\n",
        "    BertConfig,\n",
        "    BertTokenizer\n",
        ")\n",
        "\n",
        "# 트랜스포머(Transformer) 학습을 위한 라이브러리 불러오기\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# 한국어 모델 학습을 위한 정규화 라이브러리 사용\n",
        "from soynlp.normalizer import emoticon_normalize, repeat_normalize\n",
        "\n",
        "# 기타 라이브러리 불러오기\n",
        "import os\n",
        "import re\n",
        "import copy\n",
        "import json\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# 모델 학습 및 학습된 모델 평가를 위한 라이브러리\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "# 하이퍼 파라미터 정의 목적\n",
        "from argparse import Namespace\n",
        "from types import SimpleNamespace\n",
        "\n",
        "from torch.optim import AdamW\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tIBXLW5K4I-s"
      },
      "outputs": [],
      "source": [
        "args = SimpleNamespace()\n",
        "\n",
        "\n",
        "directory_path = \"/content/data\"  # 원하는 디렉토리 경로로 변경하세요.\n",
        "\n",
        "# 디렉토리 생성\n",
        "if not os.path.exists(directory_path):\n",
        "    os.makedirs(directory_path)\n",
        "else:\n",
        "    pass\n",
        "\n",
        "args.task = \"koreanNewsClassification\"  # The name of the task to train\n",
        "args.model_dir = \"./model\"  # Path to save, load model\n",
        "args.model_dir = \"./model\"  # Path to save, load model\n",
        "args.model_dir1 = \"/model\"\n",
        "\n",
        "args.data_dir = \"\"  # The input data dir\n",
        "args.input_file = \"complete_train.csv\"\n",
        "#args.input_file = \"/content/complete.csv\"\n",
        "#args.input_test_file = \"/content/test_dataset.csv\"\n",
        "args.input_test_file = \"complete_test.csv\"\n",
        "args.pred_dir = \"./preds\"  # Directory that saves prediction files\n",
        "\n",
        "args.train_file = \"train.csv\"  # Train file\n",
        "args.dev_file = \"validate.csv\"  # Dev file\n",
        "args.test_file = \"test.csv\"  # Test file\n",
        "args.prediction_file = \"prediction.csv\"  # Output file for prediction\n",
        "\n",
        "args.model_type = \"koelectra-base-v2\"  # Model type selected\n",
        "args.model_name_or_path = \"monologg/koelectra-base-v2-discriminator\"  # Model name or path\n",
        "\n",
        "args.seed = 42  # random seed for initialization\n",
        "args.train_batch_size = 16  # Batch size for training.\n",
        "args.eval_batch_size = 32  # Batch size for evaluation.\n",
        "args.max_seq_len = 512  # The maximum total input sequence length after tokenization.\n",
        "args.learning_rate = 5e-5  # The initial learning rate for Adam.\n",
        "args.num_train_epochs = 20.0  # Total number of training epochs to perform.\n",
        "args.weight_decay = 0.0  # Weight decay if we apply some.\n",
        "args.gradient_accumulation_steps = 1  # Number of updates steps to accumulate before performing a backward/update pass.\n",
        "args.adam_epsilon = 1e-8  # Epsilon for Adam optimizer.\n",
        "args.max_grad_norm = 1.0  # Max gradient norm.\n",
        "args.max_steps = -1  # If > 0: set total number of training steps to perform. Override num_train_epochs.\n",
        "args.warmup_proportion = 0.1  # Warmup proportion for linear warmup\n",
        "\n",
        "args.logging_steps = 200  # Log and save every X updates steps.\n",
        "\n",
        "args.do_train = True  # Whether to run training.\n",
        "args.do_pred = True  # Whether to run prediction on the test set.\n",
        "args.no_cuda = False  # Avoid using CUDA when available\n",
        "\n",
        "args.politic_loss_coef = 0.5  # Coefficient for the politic loss. (Changed from bias_loss_coef)\n",
        "args.government_loss_coef = 1.0  # Coefficient for the government loss. (Changed from hate_loss_coef)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MdSQt_yMEyUX"
      },
      "outputs": [],
      "source": [
        "class PoliticClassificationHead(nn.Module):\n",
        "    def __init__(self, config, num_politic_labels):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_politic_labels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GovernmentClassificationHead(nn.Module):\n",
        "    def __init__(self, config, num_government_labels):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_government_labels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z0F2LQajE8JX"
      },
      "outputs": [],
      "source": [
        "class ElectraForPoliticClassification(ElectraPreTrainedModel):\n",
        "    def __init__(self,\n",
        "                 config: ElectraConfig,\n",
        "                 args: Namespace,\n",
        "                 politic_label_lst=None,\n",
        "                 government_label_lst=None):\n",
        "        super().__init__(config)\n",
        "        self.args = args\n",
        "        self.num_politic_labels = len(politic_label_lst) if politic_label_lst is not None else 0\n",
        "        self.num_government_labels = len(government_label_lst) if government_label_lst is not None else 0\n",
        "\n",
        "        self.electra = ElectraModel(config)  # 특징 추출기\n",
        "\n",
        "        self.politic_classifier = PoliticClassificationHead(config, self.num_politic_labels)\n",
        "        self.government_classifier = GovernmentClassificationHead(config, self.num_government_labels)\n",
        "\n",
        "        self.loss_fct = nn.CrossEntropyLoss() #multi-head할 때 사용\n",
        "\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, politic_labels=None, government_labels=None):\n",
        "        discriminator_hidden_states = self.electra(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        # discriminator_hidden_states는 BaseModelOutputWithPastAndCrossAttentions의 객체 중 하나.\n",
        "        # [0]는 마지막 레이어의 hidden states로 (batch_size, sequence_length, hidden_size) 형태\n",
        "\n",
        "        # discriminator_hidden_states[0][:, 0]의 의미:\n",
        "        #   => 마지막 레이어의 hidden states 중에서 모든 배치를 유지한 상태로 첫째 sequence token만 확인 ([CLS] 토큰)\n",
        "        pooled_output = discriminator_hidden_states[0][:, 0]\n",
        "\n",
        "        politic_logits = self.politic_classifier(pooled_output)\n",
        "        government_logits = self.government_classifier(pooled_output)\n",
        "\n",
        "        total_loss = 0\n",
        "\n",
        "        if politic_labels is not None:\n",
        "            politic_loss = self.loss_fct(politic_logits.view(-1, self.num_politic_labels), politic_labels.view(-1))\n",
        "         #   total_loss += self.args.politic_loss_coef * politic_loss\n",
        "\n",
        "        if government_labels is not None:\n",
        "            government_loss = self.loss_fct(government_logits.view(-1, self.num_government_labels), government_labels.view(-1))\n",
        "            total_loss += self.args.government_loss_coef * government_loss\n",
        "\n",
        "        outputs = ((politic_logits, government_logits),) + discriminator_hidden_states[1:]\n",
        "        outputs = (total_loss,) + outputs\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "\n",
        "class BertForPoliticClassification(BertPreTrainedModel):\n",
        "    def __init__(self,\n",
        "                 config: BertConfig,\n",
        "                 args: Namespace,\n",
        "                 politic_label_lst=None,\n",
        "                 government_label_lst=None):\n",
        "        super().__init__(config)\n",
        "        self.args = args\n",
        "        self.num_politic_labels = len(politic_label_lst) if politic_label_lst is not None else 0\n",
        "        self.num_government_labels = len(government_label_lst) if government_label_lst is not None else 0\n",
        "\n",
        "        self.bert = BertModel(config)  # 특징 추출기\n",
        "\n",
        "        self.politic_classifier = PoliticClassificationHead(config, self.num_politic_labels)\n",
        "        self.government_classifier = GovernmentClassificationHead(config, self.num_government_labels)\n",
        "\n",
        "        self.loss_fct = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        politic_labels=None,\n",
        "        government_labels=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "    ):\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "        )\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "\n",
        "        politic_logits = self.politic_classifier(pooled_output)\n",
        "        government_logits = self.government_classifier(pooled_output)\n",
        "\n",
        "        total_loss = 0\n",
        "\n",
        "        if politic_labels is not None:\n",
        "            politic_loss = self.loss_fct(politic_logits.view(-1, self.num_politic_labels), politic_labels.view(-1))\n",
        "            total_loss += self.args.politic_loss_coef * politic_loss\n",
        "\n",
        "        if government_labels is not None:\n",
        "            government_loss = self.loss_fct(government_logits.view(-1, self.num_government_labels), government_labels.view(-1))\n",
        "            total_loss += self.args.government_loss_coef * government_loss\n",
        "\n",
        "        outputs = ((politic_logits, government_logits),) + outputs[2:]\n",
        "\n",
        "        outputs = (total_loss,) + outputs\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1Y1TVAoqGJQa"
      },
      "outputs": [],
      "source": [
        "\n",
        "MODEL_CLASSES = {\n",
        "    \"koelectra-base\": (ElectraConfig, ElectraForPoliticClassification, ElectraTokenizer),\n",
        "    \"koelectra-small\": (ElectraConfig, ElectraForPoliticClassification, ElectraTokenizer),\n",
        "    \"koelectra-base-v2\": (ElectraConfig, ElectraForPoliticClassification, ElectraTokenizer),\n",
        "    \"koelectra-small-v2\": (ElectraConfig, ElectraForPoliticClassification, ElectraTokenizer),\n",
        "    \"kcbert-base\": (BertConfig, BertForPoliticClassification, BertTokenizer),\n",
        "}\n",
        "\n",
        "\n",
        "def load_tokenizer(args):\n",
        "    return MODEL_CLASSES[args.model_type][2].from_pretrained(args.model_name_or_path)\n",
        "\n",
        "\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if not args.no_cuda and torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "def compute_metrics(pred_politic_labels, pred_government_labels, gt_politic_labels, gt_government_labels):\n",
        "    politic_weighted_f1 = f1_score(gt_politic_labels, pred_politic_labels, average=\"weighted\")\n",
        "    government_weighted_f1 = f1_score(gt_government_labels, pred_government_labels, average=\"weighted\")\n",
        "\n",
        "    politic_macro_f1 = f1_score(gt_politic_labels, pred_politic_labels, average=\"macro\")\n",
        "    government_macro_f1 = f1_score(gt_government_labels, pred_government_labels, average=\"macro\")\n",
        "\n",
        "    mean_weighted_f1 = (politic_weighted_f1 + government_weighted_f1) / 2\n",
        "    return {\n",
        "        \"politic_weighted_f1\": politic_weighted_f1,\n",
        "        \"government_weighted_f1\": government_weighted_f1,\n",
        "        \"mean_weighted_f1\": mean_weighted_f1,\n",
        "        \"politic_macro_f1\": politic_macro_f1,\n",
        "        \"government_macro_f1\": government_macro_f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aUNqXeH0v8Yi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_data_from_csv(filename):\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    # title, content, label1, label2에 NaN 값이 있는 행만 제거\n",
        "    df.dropna(subset=['title', 'content', 'label1', 'label2'], inplace=True)\n",
        "\n",
        "    # title과 content를 합친다.\n",
        "    df['text'] = df['title'] + \" \" + df['content']\n",
        "    df['text'] = df['text'].str.replace('\\n', '')\n",
        "\n",
        "    # 필요한 열만 선택\n",
        "    df = df[['text', 'label1', 'label2']]\n",
        "    return df\n",
        "\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\" A single training/test example for simple sequence classification. \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 guid,\n",
        "                 text,\n",
        "                 politic,\n",
        "                 government):\n",
        "        self.guid = guid\n",
        "        self.text = text\n",
        "        self.politic = politic\n",
        "        self.government = government\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "# DataFrame에서 InputExample 객체를 생성하는 함수\n",
        "def create_examples_from_dataframe(df, set_type):\n",
        "    examples = []\n",
        "    for index, row in df.iterrows():\n",
        "        guid = \"%s-%s\" % (set_type, index)\n",
        "        text = row['text']\n",
        "        politic = row['label1']\n",
        "        government = row['label2']\n",
        "\n",
        "        examples.append(InputExample(guid=guid,\n",
        "                                     text=text,\n",
        "                                     politic=politic,\n",
        "                                     government=government))\n",
        "    return examples\n",
        "\n",
        "\n",
        "# 주어진 CSV 파일 경로\n",
        "filename = os.path.join(args.data_dir, args.input_file)\n",
        "df = load_data_from_csv(filename)\n",
        "\n",
        "\n",
        "# 데이터셋 분리\n",
        "train_df, valid_df = train_test_split(df, train_size=4000,  random_state=args.seed, stratify=None)\n",
        "test_df = os.path.join(args.data_dir, args.input_test_file)\n",
        "test_df = load_data_from_csv(test_df)\n",
        "\n",
        "\n",
        "# 분리된 데이터셋을 각각의 파일로 저장\n",
        "train_df.to_csv(os.path.join(args.data_dir, args.train_file), index=False)\n",
        "valid_df.to_csv(os.path.join(args.data_dir, args.dev_file), index=False)\n",
        "test_df.to_csv(os.path.join(args.data_dir, args.test_file), index=False)\n",
        "\n",
        "\n",
        "# InputExample 객체 생성\n",
        "train_examples = create_examples_from_dataframe(train_df, \"train\")\n",
        "valid_examples = create_examples_from_dataframe(valid_df, \"dev\")\n",
        "test_examples = create_examples_from_dataframe(test_df, \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G5R8s72NC2X",
        "outputId": "b97fbc34-ad72-4932-f2cb-22824e85ef2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000\n"
          ]
        }
      ],
      "source": [
        "print(len(train_examples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BgV-Tnz6GOdv"
      },
      "outputs": [],
      "source": [
        "# 하나의 텍스트 입력의 특징(feature)에 대한 클래스\n",
        "import ast\n",
        "import csv\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, attention_mask, token_type_ids, politic_label, government_label):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.politic_label = politic_label\n",
        "        self.government_label = government_label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "# 한국어 뉴스 기사 및 댓글 전처리 기능 클래스\n",
        "class KoreanNewsProcessor(object):\n",
        "    \"\"\"Processor for the Korean News data set \"\"\"\n",
        "\n",
        "    def __init__(self, args):\n",
        "        self.args = args\n",
        "\n",
        "    @classmethod\n",
        "    def get_labels(cls):\n",
        "        politic_lst = [str(i) for i in range(1, 6)]  # '1' to '5'\n",
        "        government_lst = [str(i) for i in range(0, 6)]  # '0' to '5'\n",
        "        return politic_lst, government_lst\n",
        "\n",
        "    @classmethod\n",
        "    def _read_file(cls, input_file):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            lines = []\n",
        "            for line in f:\n",
        "                lines.append(line.strip())\n",
        "            return lines\n",
        "\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the train, dev and test sets.\"\"\"\n",
        "        examples = []\n",
        "        reader = csv.reader(lines[1:], delimiter=',', quotechar='\"')\n",
        "\n",
        "        for i, parsed_line in enumerate(reader):\n",
        "            if len(parsed_line) < 3 and set_type != \"test\":\n",
        "                print(f\"Error in line {i+1}: {parsed_line}\")\n",
        "                continue\n",
        "            guid = \"%s-%s\" % (set_type, i)\n",
        "            text = parsed_line[0]\n",
        "\n",
        "            politic = None\n",
        "            government = None\n",
        "           # if set_type != \"test\":\n",
        "            politic = parsed_line[1]\n",
        "            government = parsed_line[2]\n",
        "            if i % 1000 == 0:\n",
        "                print(text)\n",
        "\n",
        "            examples.append(InputExample(guid=guid,\n",
        "                                        text=text,\n",
        "                                        politic=politic,\n",
        "                                        government=government))\n",
        "        return examples\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def get_examples(self, mode):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            mode: train, dev, test\n",
        "        \"\"\"\n",
        "        file_to_read = None\n",
        "        if mode == 'train':\n",
        "            file_to_read = self.args.train_file\n",
        "        elif mode == 'dev':\n",
        "            file_to_read = self.args.dev_file\n",
        "        elif mode == 'test':\n",
        "            file_to_read = self.args.test_file\n",
        "\n",
        "        print(\"LOOKING AT {}\".format(os.path.join(self.args.data_dir, file_to_read)))\n",
        "        return self._create_examples(self._read_file(os.path.join(self.args.data_dir, file_to_read)), mode)\n",
        "\n",
        "# 실질적으로 텍스트 입력을 트랜스포머 모델에 넣어 특징(feature)을 계산하는 함수\n",
        "def convert_examples_to_features(examples, tokenizer, max_length):\n",
        "    # 라벨 리스트를 가져옵니다.\n",
        "    politic_label_list, government_label_list = KoreanNewsProcessor.get_labels()\n",
        "\n",
        "    # 라벨을 인덱스로 매핑합니다.\n",
        "    politic_label_map = {label: i for i, label in enumerate(politic_label_list)}\n",
        "    government_label_map = {label: i for i, label in enumerate(government_label_list)}\n",
        "\n",
        "    def label_from_example(example):\n",
        "        politic_label_id = -1\n",
        "        government_label_id = -1\n",
        "        if example.politic is not None:\n",
        "            politic_label_id = politic_label_map[example.politic]\n",
        "        if example.government is not None:\n",
        "            government_label_id = government_label_map[example.government]\n",
        "        return politic_label_id, government_label_id\n",
        "\n",
        "    labels = [label_from_example(example) for example in examples]\n",
        "\n",
        "    texts = [example.text for example in examples]\n",
        "\n",
        "    batch_encoding = tokenizer.batch_encode_plus(texts, max_length=max_length, padding='max_length', truncation=True)\n",
        "\n",
        "    features = []\n",
        "    for i in range(len(examples)):\n",
        "        inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
        "        if \"token_type_ids\" not in inputs:\n",
        "            inputs[\"token_type_ids\"] = [0] * len(inputs[\"input_ids\"])  # For models like xlm-roberta\n",
        "\n",
        "        feature = InputFeatures(input_ids=inputs[\"input_ids\"],\n",
        "                        attention_mask=inputs[\"attention_mask\"],\n",
        "                        token_type_ids=inputs[\"token_type_ids\"],\n",
        "                        politic_label=labels[i][0],\n",
        "                        government_label=labels[i][1])\n",
        "\n",
        "        features.append(feature)\n",
        "\n",
        "    for i, example in enumerate(examples[:5]):\n",
        "        print(\"*** Example ***\")\n",
        "        print(\"guid: {}\".format(example.guid))\n",
        "        print(\"input_ids: {}\".format(\" \".join([str(x) for x in features[i].input_ids])))\n",
        "        print(\"attention_mask: {}\".format(\" \".join([str(x) for x in features[i].attention_mask])))\n",
        "        print(\"token_type_ids: {}\".format(\" \".join([str(x) for x in features[i].token_type_ids])))\n",
        "        print(\"politic_label: {}\".format(features[i].politic_label))\n",
        "        print(\"government_label: {}\".format(features[i].government_label))\n",
        "\n",
        "    print(\"Number of features:\", len(features))\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "\n",
        "def load_examples(args, tokenizer, mode):\n",
        "    processor = KoreanNewsProcessor(args)\n",
        "\n",
        "    print(\"Creating features from dataset file at %s\", args.data_dir)\n",
        "    if mode == \"train\":\n",
        "        examples = processor.get_examples(\"train\")\n",
        "    elif mode == \"dev\":\n",
        "        examples = processor.get_examples(\"dev\")\n",
        "    elif mode == \"test\":\n",
        "        examples = processor.get_examples(\"test\")\n",
        "    else:\n",
        "        raise Exception(\"For mode, Only train, dev, test is available\")\n",
        "\n",
        "    features = convert_examples_to_features(\n",
        "        examples,\n",
        "        tokenizer,\n",
        "        args.max_seq_len\n",
        "    )\n",
        "\n",
        "    # Convert to Tensors and build dataset\n",
        "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "    all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
        "    all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
        "    all_politic_labels = torch.tensor([f.politic_label for f in features], dtype=torch.long)  # 수정\n",
        "    all_government_labels = torch.tensor([f.government_label for f in features], dtype=torch.long)  # 수정\n",
        "\n",
        "    dataset = TensorDataset(all_input_ids,\n",
        "                            all_attention_mask,\n",
        "                            all_token_type_ids,\n",
        "                            all_politic_labels,  # 수정\n",
        "                            all_government_labels)  # 수정\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTF94gPBcls2",
        "outputId": "2c0b25eb-3911-46f6-b432-6bbe14f45e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOOKING AT train.csv\n",
            "자체 핵무장론 펴는 남북대결주의자에 통일부 맡겨 신임 통일부 장관 후보자에 지명된 김영호 성신여대 정치외교학과 교수가 29일 인사청문회 준비 사무실이 마련된 서울 종로구 남북회담본부에 도착해 장관 후보자가 된 입장을 밝히고 있다. 연합뉴스윤석열 대통령이 29일 통일부 장관 후보자로 김영호(64) 성신여대 교수(정치외교학)를 지명하고, 통일부 차관으로는 외교부 출신인 문승현(59) 주태국(타이)대사를 기용하면서 통일부 장차관이 모두 외부 인사로 채워지게 됐다. 통일부 장차관이 모두 외부인으로 채워진 것은 김영삼 정부 때의 ‘권오기 장관, 김석우 차관’ 체제 이후 25년 만이다. 특히 김영호 후보자는 그동안 “김정은 정권 타도”를 주장하고 여러차례 자체 핵무장을 강조한 ‘남북대결주의자’라는 점에서, 대북·통일 정책을 펼쳐야 할 통일부를 형해화하는 인선이라는 지적이 나온다.김 후보자는 그동안 언론 기고와 유튜브 등을 통해 적대적 대북관을 내보이고, 자체 핵무장과 미국 전술핵 한반도 재배치를 주장해왔다. 그는 2019년 4월18일 인터넷 매체 <펜앤드마이크> 기고에서 “김정은 정권이 타도되고 북한 자유화가 이루어져서 남북한 정치체제가 ‘1체제’가 되었을 때 통일의 길이 비로소 열리게 된다”고 주장했다. 2018년 9월13일 같은 매체에 기고한 글에서는 “남북관계는 적대관계”라고 주장했다. 지난 2월20일 유튜브에서는 “미국은 한국에 전술핵무기를 재배치하는 것을 적극적으로 고려해야 되고 한국도 미국에 그런 요구를 강력하게 해야 될 시점”이라며 미국 전술핵의 한반도 재배치 필요성을 주장했다.“남북관계는 적대관계”라서 “김정은 정권 타도”로 통일의 길을 열어야 한다는 김 후보자의 주장은 ‘강압적 흡수통일론’으로 볼 수 있다. 이는 “흡수통일을 추구하지 않는다”는 윤석열 정부 공식 방침과 배치된다. 전술핵 재배치 주장 또한 정부 입장에 반한다. 권영세 통일부 장관은 지난해 10월 국회 국정감사에서 여권 일각에서 주장하는 전술핵 재배치에 대해 “정부 입장은 아니다. 찬성하지 않는다”고 말했다.윤 대통령은 노골적인 적대적 대북관을 지닌 김영호 후보자를 장관에 기용한 것에 더해, 주미대사관 정무공사 등을 지낸 정통 외교관 문승현 대사를 차관에 내정했다. 이는 윤 대통령이 통일부의 기능과 성격을 대대적으로 바꿔 사실상 ‘북한인권부’로 바꾸겠다는 신호라는 풀이가 나온다. 통일부가 그간 주도해온 남북 대화·교류보다는 국제사회와 함께 북한 인권 문제를 부각하면서 대북 압박에 주력할 것이라는 관측에서다. 윤 대통령은 이날 대통령실 통일비서관에 국내외 인권 문제를 연구한 김수경 한신대 교수(사회복지학)를 내정한 것으로 알려졌는데, 이 또한 같은 맥락으로 해석된다.양무진 북한대학원대학교 교수는 “대화와 협력을 통한 평화통일을 지향하는 통일부가 아니라 대립과 대결을 통해 흡수통일을 지향하는 ‘대결부’ 또는 ‘북한흡수부’의 출발을 알리는 인사”라고 평가했다.외부 출신 장차관을 맞이하는 통일부는 뒤숭숭한 분위기다. 한 직원은 “통일부에 업무와 접근 방식, 구성원의 마인드 등 조직 정체성을 완전히 바꾸라는 요구인 것 같다”고 <연합뉴스>에 말했다.김 후보자는 이날 기자들에게 “원칙을 갖고 북핵 문제 해결과 남북관계 개선을 위한 기반을 닦기 위해 노력하겠다”고 말했다. 그는 ‘북한 정권이 타도돼야 통일을 할 수 있다는 생각에는 변함이 없는가’라는 물음에 “일부에서는 그렇게 보도가 됐는데, 제가 쓴 글이 있으니까 글을 잘 읽어보시면 그 문맥을 잘 이해할 수 있을 것”이라고 했다. 또 ‘대북 강경파로 알려졌는데, 통일부 장관으로서 교류와 협력을 하는 역할을 잘 수행할 수 있겠는가’라는 질문에는 “우려에 대해서는 청문회 과정에서 자세하게 말씀드리도록 하겠다”고 답했다.신형철 기자 newiron@hani.co.kr\n",
            "국토부에 경찰 권한 준다? '건폭 때리기' 당정협의, 문제점은… 정부·여당이 윤석열 정부 출범 1년에 즈음해 국토교통부 공무원에게 수사권 등 특수사법경찰 권한을 주는 방안, 건설기계 운송 거부 제재 강화 방안 등을 입법화하겠다는 입장을 밝혔다. 타워크레인에 스마트 작업기록장치를 부착하는 방안도 추진된다. 노동계에서는 '건설노조 때리기'에 더욱 열을 올리려는 행보라며 반발이 나왔다. 건설현장 갈등의 주 원인인 불법 하도급 근절을 위한 근본적인 대책 마련에는 소홀하다는 지적도 이어졌다.국민의힘과 정부는 지난 11일 국회에서 민·당·정 협의회를 열고 '건설현장 정상화 5대 법안' 개정을 조속히 추진하겠다고 밝혔다. 입법 작업은 국토부, 고용노동부, 법무부의 지원 하에 진행된다.당일 국토부가 발표한 '건설현장 불법행위 근절 후속대책'을 보면, 5대 법안 중 가장 먼저 눈에 띄는 것은 법무부 소관인 사법경찰직무법 개정안이다. 국토부 공무원에게 특별사법경찰 권한을 부여해 건설현장의 불법행위를 직접 수사·단속할 수 있게 하겠다는 내용이다.국토부는 △ 건설기계를 이용한 공사방해, 부당금품 요구, 정당한 사유 없는 운송거부 제재를 명시하는 건설기계관리법 개정안 △ 불법하도급·부실시공에 대한 형사처벌·행정처분 강화와 징벌적 손해배상제 도입 및 임금체불 방지를 위한 대금지급시스템, 불법행위 신고포상제 등을 담은 건설산업기본법 개정안을 담당한다.국토부 자료에는 안전운행, 노무관리 등을 위해 타워크레인 스마트 작업기록장치 부착을 추진한다는 내용도 포함됐는데, 이는 공사방해, 운송거부 단속에도 활용될 가능성이 있다.고용노동부는 △ 채용강요 제재를 과태료에서 형벌로 강화하는 채용절차법 개정안 △ 노동조합의 노동자·사용자 권리 침해, 대체근로 및 사업장 점거 등과 관련한 제도 개편을 위한 노동조합법 개정안을 맡았다.이 중 사법경찰법·건설기계법 개정안과 건설산업법 개정안 일부, 노조법 개정안 일부는 여당 의원 입법 형식으로 이미 국회에 발의됐다. 국토부는 오는 8월까지 나머지 법안도 발의할 계획이라고 밝혔다.▲민주노총 양경수 위원장이 4일 오후 서울 종로구 서울대병원 장례식장에 마련된 민주노총 건설노조 강원지부 간부 양회동씨 빈소를 찾아 조문하고 있다. ⓒ연합뉴스이른바 '5대 법안'에 대해 건설노조는 즉각 반발 입장을 밝혔다. 건설노조는 11일 낸 입장문에서 \"대책 대부분이 건설사의 불법행위에는 상징적 선언과 도구적 차원의 제도 개선에 머무르는 반면, 노동자에 대한 제재는 생존권 파괴 수준의 조치를 구체적으로 담고 있다는 점에서 극히 비대칭적으로 구성돼 있다\"고 지적했다.이어 국토부가 대책 설명 뒤에 붙인 참고자료에서 월례비와 노조 전임비를 \"불법·부당 금품 수수 현황\"으로 분류한 데 대해서도 건설노조는 \"월례비의 원인인 위험한 편법 작업 요구는 놔둔 채 결과인 월례비 수수만 금지해서 월례비는 사라지지 않는다\"며 \"노동법상으로 보장된 근로시간 면제제도를 '노조 전임비 강요'로 전제한 후 전임비 전체를 불법인 양 서술하고 있다\"고 편향성을 지적했다.건설노조는 \"문제의 핵심은 불법하도급\"이라며 정부의 관련 대책에 대해 \"고용 문제에 어떤 언급도 없다는 점에서 아무 대책도 아니다. 불법하도급을 처벌할 제도와 밝혀낼 방법이 없어서 불법하도급이 수십 년 간 내려온 게 아니다. 노동자의 고용 문제를 풀 의지가 없었기 때문에 불법하도급이 끊이질 않았던 것\"이라고 강조했다.건설노조는 \"다시 한번 노동자-사용자-정부-전문가로 구성된 건설업 혁신을 위한 대화기구를 만들 것을 제안한다\"며 \"이 대책이 시행되고 나서 발생할 문제들은 불을 보듯 뻔하다. 문제가 걷잡을 수 없이 커지기 전에 대화와 소통을 통해 대안을 마련하자\"고 촉구했다.\n",
            "박대출 \"우주항공청법 표류 중…7대 우주강국 가는 길 막지 말라\"  박대출 국민의힘 정책위의장이 28일 오전 서울 여의도 국회에서 열린 유·보 관리체계 일원화 방안 관련 당·정협의회에서 발언을 하고 있다. 2023.7.28/뉴스1 © News1 임세영 기자박대출 국민의힘 정책위의장은 28일 더불어민주당을 향해 \"7대 우주강국으로 가는 길을 더이상 막지 말기 바란다\"며 우주항공청 설치의 근거가 되는 '우주항공청의 설치 및 운영에 관한 특별법'을 조속히 심사해 달라고 촉구했다.  박 정책위의장은 이날 국회에서 열린 원내대책회의에서 \"우주항공청 특별법이 거대 야당의 어처구니 없는 몽니에 걸려서 하염없이 표류 중\"이라며 \"세계 주요국들은 우주 선점을 위해 치열한 경쟁을 마다하지 않는데 대한민국 주요 미래먹거리인 우주항공산업이 야당에 발목 잡혀 있는 현실이 참담하기만 하다\"고 밝혔다.   박 정책위의장은 \"국민의힘은 특별법의 신속한 통과를 위해 민주당이 요구한 안건 조정 (요구)도 신속히 수용했다\"며 \"그럼에도 어제 안건조정위는 민주당 불참으로 열리지도 못했다\"고 말했다. 이어 \"우주항공산업 육성은 지난 대선 때 이재명 민주당 대표의 핵심 공약이었다\"면서 \"지난 5월 누리호 3차 발사 성공으로 우리나라는 우주 7대 강국으로 도약하는 계기를 마련했지만 우주선진국과 격차를 좁히려면 아직 갈 길이 멀고도 험하다\"고 했다. 그러면서 \"민주당은 지난 대선 때 국민들에게 드렸던 우주항공청 설립 약속을 지켜야 한다\"며 \"더이상 시간을 질질 끌지 말고 조속히 법안 심사에 나서주기 바란다\"고 민주당의 태도 변화를 촉구했다. 윤석열 정부 핵심 국정과제 중 하나인 우주항공청 설치는 과방위가 두 달 가까이 공회전하면서 법안 통과가 늦어지고 있다. 특별법은 전날 상임위에서 결론을 내지 못한 채 안건조정위원회로 회부됐으나, 안조위는 첫날부터 파행됐다. 민주당 안조위원들이 '다수당 소속 조정위원 중 위원장을 선출한다'는 국회법 제57조의2 5항에 따라 과방위 민주당 간사 조승래 의원을 위원장으로 추천했으나, 국민의힘은 조 의원 대신 변재일 민주당 의원을 추천한다는 입장을 밝히면서다.박 정책위의장은 또한 '서울-양평고속도로 노선 변경 관련 대통령 처가 특혜 의혹에 대한 진상규명을 위한 국정조사 요구서'를 민주당 소속 의원 전원 명의로 제출한 데 대해 \"답정너(답은 정해져 있으니 너는 대답만 해) 국조\"라며 철회를 요구했다. 그는 \"양평 고속도로 노선 변경 검토는 문재인 정부 때 이뤄졌음이 밝혀졌음에도 민주당은 어깃장 정치를 계속하고 있다\"고 비판했다. 이어 \"민주당이 답정너 국조를 벌인 이유는 너무 뻔하다. 8월 소환서를 물타기하는 국면 전환용 국조이고 이재명 대표 방탄이 목적인 것\"이라고 꼬집었다. 그러면서 \"민주당은 가짜뉴스 공장 문을 닫고 반대를 위한 반대, 이재명 방탄을 위한 국조 요구를 지금이라도 철회하기 바란다\"고 덧붙였다.\t\t\t\tangela0204@news1.kr                \t\t\t\n",
            "GDP 250조' 우크라 재건에 2000조?…전쟁 나라에서 尹의 민망한 '잿밥 외교' 대통령실이 우크라이나 재건사업 규모를 '2000조 원'으로 파악하고 있다는 보도들이 쏟아져 나오고 있다. 2000조 원은 한국의 1년 GDP에 해당하는 엄청난 규모다. 그중에 한국 몫은 66조 원이라고 한다.'2000조 원'이라는 규모의 출처는 명확하지도 않다. 지난 14일 <파이낸셜뉴스>가 \"대통령실은 우크라이나 재건 사업에 대해 '2000조 원 이상 규모의 공사와 경제 사업이 따를 것으로 추정된다'고 밝혔다\"고 보도했다. 한국 정부의 '몫'이 이 중 66조 원이라는 보도도 나왔다. 대통령실이 직접 '2000조 원'을 언급했다.이 매체는 원래 우크라이나 재건 사업이 최대 1조 달러(약 1270조 원) 이상으로 평가됐지만 \"2000조 원 이상으로 평가가치가 높아진 것을 놓고 대통령실 고위관계자는 '중장기적으로 보면 우크라이나가 스스로 산정하지 못한 장기적인 인프라 건설에 추가 소요가 발견될 수 있다'고 설명했다\"고 전했다.이번 순방을 계기로 대통령실 측이 우크라이나 재건 비용을 '2000조 원' 규모로 추산한 셈이다. 갑자기 700조 원 안팎이 훅 늘어났다.대통령실은 우크라이나 방문을 순방 중에 결정한 이유에 대해 '전후 재건 사업 참여'를 명분으로 내세우고 있다.<중앙일보>는 17일 \"윤 대통령의 재건 사업을 강조한 배경과 관련 대통령실 최상목 경제수석은 지난 14일 폴란드와 우크라이나 재건 협력 양해각서를 체결한 이후 기자들과 만나 '우크라이나는 전쟁 피해를 복구하는 리빌딩을 넘어, 국가 시스템을 업그레이드하는 뉴빌딩을 추진 중\"이라며 향후 재건 사업이 단순한 재건과 복구 수준을 넘어선 규모가 될 가능성을 시사했다\"고 전했다. 이 매체는 \"선진국들 역시 우크라이나 재건 사업이 제2차 세계대전 이후 미국이 유럽 16개국을 지원했던 '제2의 마셜플랜'이 될 가능성이 클 것으로 전망하고 있다\"고 보도하기도 했다.그런데 2000조 원 규모라는 건 대체 어디에서 나온 걸까.당초 '1조 달러'라는 수치는 우크라이나 정부 측이 제시한 안을 토대로 추정한 것으로 보인다. 앞서 <연합뉴스>는 두 달여 전인 지난 5월 22일 폴란드 바르샤바에서 개최된, 한국·폴란드·우크라이나 3국 민간 단체 주축의 '우크라이나 재건을 위한 국제콘퍼런스' 소식을 전하며 \"우크라이나 정부가 추정하는 재건사업 규모는 9000억 달러(약 1200조 원)에 달해 21세기판 마셜플랜으로 불린다\"고 전했다. 이건 '민간 단체'들이 '정부'를 인용해 낸 추산이다.두 달 만에 이번 윤석열 대통령 순방 도중 재건 사업 규모가 2000조 원으로 상승했다.먼저 이같은 규모의 재건 사업 비용이 어디에서 충당될 것이냐는 의문이 든다. 정부가 인용하는 '마셜플랜'은 미국이 전후 유럽 재건을 위해 130억 달러를 쏟아 부었던 사례를 말한다. 당시엔 현금과 현물을 쥔 미국이라는 확실한 자금 출처가 있었다. 미국은 서유럽 국가를 비롯한 20여개 국에 직접 돈을 댔다. 하지만 우크라이나 재건 사업은 결이 다르다. 유럽과 우크라이나 단일 국가, 규모도 비교 불가다. 자본주의 발전과 함께 유럽의 성장이 미국에 시장을 확보해 준 것처럼, 지금은 자본주의 고도화로 이행되는 기간도 아니다. 무엇보다 2000조 원을 누가 지불할지 알 수 없다.우크라이나 GDP는 전쟁 이전인 2021년 2000억 달러 수준이다. 약 253조 원이다. '재건 비용'은 우크라이나 GDP의 8배에 해당한다.한국 코트라에 따르면 2022년 우크라이나가 받은 해외 원조는 약 320억 달러이며, 그중 140억 달러가 무상원조다. 국방비 지출에 허덕이는 우크라이나의 총 수입은 600억 달러고, 총 지출은 832억 달러다. 코트라는 \"2023년 우크라이나 경제전망과 관련해서 국제기구나 우크라이나 정부 및 기관에서 내놓은 수치를 보면, 비교적 편차가 심한 편이다. 현재의 사태가 언제 끝날지 알 수 없는 상황으로 전망에 대한 의견도 분분한 것이라고 이해된다\"고 했다.실제 우크라이나 경제부는 2023년 GDP 성장률을 3.2%로 보고 있지만, 국제통화기금(IMF)은 1%로 보고 있다. 전쟁 수행 중인 국가이기 때문에 경제 전망이 들쭉날쭉다. 현재 우크라이나는 막대한 재정 적자를 주로 유럽과 미국의 해외 원조로 충당하고 있다.재건사업은 결국 '투자 유치'로 가능한데, 지급보증을 설 만한 곳은 마땅치 않다. 문제는 투자금 회수다. 우크라이나의 경제 규모가 애당초 크지 않고 농업 중심 산업이 발전했다는 것도 '투자 회수' 문제와 관련해 불투명성을 높인다. '중동 특수'에 빗대는데, 우크라이나는 '오일머니'를 가진 나라도 아니고, 지금 세계가 1970년대인 것도 아니다.돌이켜보면, 이명박 정부는 G20 정상회의에서 450조 원의 경제 효과가 있다고 했다.(G20이라는 조직 자체가 지금 유명무실하다.) 윤석열 정부 들어선 후 전경련 산하 연구원은 청와대 개방만 해도 2000억 원의 경제 효과가 있다고 했다. 그 돈은 지금 다 어디로 갔을까?'2000조 원'의 장빛 환상을 말하기엔 성급하다. '종전'도 안 한 나라에서 '2000조 원'을 찾는 '잿밥 외교'도 민망하기 그지없다.▲볼로디미르 젤렌스키 우크라이나 대통령이 15일(현지시간) 우크라이나 수도 키이우의 대통령 관저인 마린스키궁에서 열린 한-우크라이나 정상회담 공동 언론발표에서 윤석열 대통령의 발언을 경청하고 있다. ⓒ연합뉴스\n"
          ]
        }
      ],
      "source": [
        "processor = KoreanNewsProcessor(args)\n",
        "examples = processor.get_examples(\"train\")\n",
        "texts = [example.text for example in examples]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE5LQFSVoK92",
        "outputId": "525fe4db-9c7e-4f06-bf9f-1b9668651bae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOOKING AT test.csv\n",
            "민주당 \"윤석열 정부의 정치생명, 원희룡 입에 달려있다\" 더불어민주당이 '양평 고속도로 백지화' 관련 원희룡 장관에게 \"가짜뉴스 유포 그만하고 사전에 사업 백지화를 재가 받았는지 밝히라\"고 촉구했다.강선우 민주당 대변인은 7일 서면브리핑에서 \"원희룡 장관이 지금 해야 할 일은 서울-양평 고속도로 종점 변경을 둘러싸고 꼬리를 무는 의문에 답하는 것\"이라며 이 같이 밝혔다.그는 \"원희룡 장관이 라디오에 출연해 '민주당이 먼저 발표된 노선대로의 변경을 요청했다'며 우리 당 최재관 지역위원장, 정동균 당시 양평군수에게 책임을 덮어씌웠다\"면서 \"이는 새빨간 거짓말이다. 주무장관이라는 사람이 국책 사업에 대해서 사실도 확인하지 않고 가짜뉴스를 유포하고 있으니 어처구니없다\"고 주장했다.그는 \"팩트를 알려드리겠다. 2년 전에는 변경안 자체가 없었다. 그리고 당시 당정협의를 거쳐 설치하고자 했던 나들목은 강하면 방면이었다\"면서 \"입을 열 때마다 하나같이 가짜뉴스로 국민을 선동하고 있으니 이쯤되면 국토교통부 장관이 아니라 국민선동부 장관 아닌가. 원희룡 장관, 혹시 롤모델이 괴벨스인가\"라고 반문했다.그는 \"사업 백지화에 비판이 쏟아지니 백지화의 책임을 민주당에 덮어씌우려는 원희룡 장관의 나름의 기만술은 처량하고 한심하다\"며 \"원희룡 장관은 가짜뉴스 유포 그만하고, 사전에 사업 백지화를 윤석열 대통령에게 재가 받았는지나 밝혀라\"라고 촉구했다.그는 \"원희룡 장관이 판돈으로 건 것은 자신의 정치생명으로 그치지 않을 것\"이라며 \"윤석열 정부의 정치생명이 원희룡 장관의 입에 달렸음을 명심하고 성실하게 답하라\"고 촉구했다.\n"
          ]
        }
      ],
      "source": [
        "examples_test = processor.get_examples(\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tre3QRj8VKvB"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(politic_preds, government_preds, politic_labels, government_labels):\n",
        "    politic_accuracy = accuracy_score(politic_labels, politic_preds)\n",
        "    government_accuracy = accuracy_score(government_labels, government_preds)\n",
        "\n",
        "    politic_f1 = f1_score(politic_labels, politic_preds, average='weighted')\n",
        "    government_f1 = f1_score(government_labels, government_preds, average='weighted')\n",
        "\n",
        "    politic_f1_macro = f1_score(politic_labels, politic_preds, average='macro')\n",
        "    government_f1_macro = f1_score(government_labels, government_preds, average='macro')\n",
        "\n",
        "    mean_weighted_f1 = (politic_f1+government_f1)/2\n",
        "    mean_macro_f1 = (politic_f1+government_f1)/2\n",
        "\n",
        "    #절대 오차 구하기\n",
        "    tolerance = 1\n",
        "\n",
        "    politic_absolute_errors = [abs(pred - true) for pred, true in zip(politic_preds, politic_labels)]\n",
        "    politic_within_tolerance = [error <= tolerance for error in politic_absolute_errors]\n",
        "\n",
        "    government_absolute_errors = [abs(pred - true) for pred, true in zip(government_preds, government_labels)]\n",
        "    government_within_tolerance = [error <= tolerance for error in government_absolute_errors]\n",
        "\n",
        "    #절대 오차 라벨 정확도\n",
        "    politic_abs_error_accuracy = sum(politic_within_tolerance) / len(politic_preds)\n",
        "    government_abs_error_accuracy = sum(government_within_tolerance) / len(government_preds)\n",
        "\n",
        "    #절대 오차 라벨 F1 점수\n",
        "    politic_abs_error_f1 = f1_score([1 if within else 0 for within in politic_within_tolerance], [1] * len(politic_labels)) #모든 라벨을 1로 만들고(실제 라벨 값은 모두 정답이니까), 절대 오차 안에 있으면1, 아니면 0으로 이진분류로 f1 구하기.\n",
        "    government_abs_error_f1 = f1_score([1 if within else 0 for within in government_within_tolerance], [1] * len(government_labels))\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"politic_accuracy\": politic_accuracy,\n",
        "        \"government_accuracy\": government_accuracy,\n",
        "\n",
        "        \"politic_weighted_f1\": politic_f1,\n",
        "        \"government_weighted_f1\": government_f1,\n",
        "\n",
        "        \"politic_f1_macro\": politic_f1_macro,\n",
        "        \"government_f1_macro\": government_f1_macro,\n",
        "\n",
        "        \"politic_abs_error_accuracy\" : politic_abs_error_accuracy,\n",
        "        \"government_abs_error_accuracy\" : government_abs_error_accuracy,\n",
        "\n",
        "        \"politic_abs_error_f1\": politic_abs_error_f1,\n",
        "        \"government_abs_error_f1\" : government_abs_error_f1,\n",
        "\n",
        "        \"politic_absolute_errors\" : politic_absolute_errors,\n",
        "        \"government_absolute_errors\" : government_absolute_errors\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MHuARqOvGfM5"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.module import register_module_buffer_registration_hook\n",
        "train_losses =[]\n",
        "val_losses =[]\n",
        "train_accuracies =[]\n",
        "val_accuracies =[]\n",
        "train_f1_scores =[]\n",
        "val_f1_scores =[]\n",
        "\n",
        "class Trainer(object):\n",
        "    def __init__(self, args, tokenizer, train_dataset=None, dev_dataset=None, test_dataset=None):\n",
        "        self.args = args\n",
        "        self.tokenizer = tokenizer\n",
        "        self.train_dataset = train_dataset\n",
        "        self.dev_dataset = dev_dataset\n",
        "        self.test_dataset = test_dataset\n",
        "\n",
        "        self.politic_label_lst, self.government_label_lst = KoreanNewsProcessor.get_labels()  # 변경\n",
        "\n",
        "        self.config_class, self.model_class, _ = MODEL_CLASSES[args.model_type]\n",
        "\n",
        "        self.config = self.config_class.from_pretrained(args.model_name_or_path,\n",
        "                                                        finetuning_task=args.task)\n",
        "        self.model = self.model_class.from_pretrained(args.model_name_or_path,\n",
        "                                                      config=self.config,\n",
        "                                                      args=args,\n",
        "                                                      politic_label_lst=self.politic_label_lst,  # 변경\n",
        "                                                      government_label_lst=self.government_label_lst)  # 변경\n",
        "\n",
        "        # GPU or CPU\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
        "        self.model.to(self.device)\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        train_sampler = RandomSampler(self.train_dataset)\n",
        "        train_dataloader = DataLoader(self.train_dataset, sampler=train_sampler, batch_size=self.args.train_batch_size)\n",
        "\n",
        "        if self.args.max_steps > 0:\n",
        "            t_total = self.args.max_steps\n",
        "            self.args.num_train_epochs = self.args.max_steps // (len(train_dataloader) // self.args.gradient_accumulation_steps) + 1\n",
        "        else:\n",
        "            t_total = len(train_dataloader) // self.args.gradient_accumulation_steps * self.args.num_train_epochs\n",
        "\n",
        "        # Prepare optimizer and schedule (linear warmup and decay)\n",
        "        no_decay = ['bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "             'weight_decay': self.args.weight_decay},\n",
        "            {'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.args.learning_rate, eps=self.args.adam_epsilon)\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                    num_warmup_steps=int(t_total * self.args.warmup_proportion),\n",
        "                                                    num_training_steps=t_total)\n",
        "\n",
        "        # Train!\n",
        "        print(\"***** Running training *****\")\n",
        "        print(\"  Num examples = %d\", len(self.train_dataset))\n",
        "        print(\"  Num Epochs = %d\", self.args.num_train_epochs)\n",
        "        print(\"  Total train batch size = %d\", self.args.train_batch_size)\n",
        "        print(\"  Gradient Accumulation steps = %d\", self.args.gradient_accumulation_steps)\n",
        "        print(\"  Total optimization steps = %d\", t_total)\n",
        "        print(\"  Logging steps = %d\", self.args.logging_steps)\n",
        "\n",
        "        global_step = 0\n",
        "        tr_loss = 0.0\n",
        "        best_mean_weighted_f1 = 0.0\n",
        "        best_politic_acc = 0.0\n",
        "        best_government_acc = 0.0\n",
        "\n",
        "        self.model.zero_grad()\n",
        "\n",
        "     #   correct_predictions = 0\n",
        "     #   total_predictions = 0\n",
        "\n",
        "\n",
        "        train_iterator = trange(int(self.args.num_train_epochs), desc=\"Epoch\", initial=1)\n",
        "        a = 0\n",
        "        for _ in train_iterator:\n",
        "            a += 1\n",
        "            print()\n",
        "            print(\"Epoch: \",a, end=\"\")\n",
        "\n",
        "            #epoch마다 정확도 및 손실 찍기 위한 것\n",
        "            politic_preds = None\n",
        "            politic_out_label_ids = None\n",
        "            government_preds = None\n",
        "            government_out_label_ids = None\n",
        "\n",
        "            tr_batch_loss = 0\n",
        "\n",
        "            epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
        "            for step, batch in enumerate(epoch_iterator):\n",
        "\n",
        "                self.model.train()\n",
        "                batch = tuple(t.to(self.device) for t in batch)  # GPU or CPU\n",
        "                inputs = {'input_ids': batch[0],\n",
        "                          'attention_mask': batch[1],\n",
        "                          'politic_labels': batch[3],  # 변경\n",
        "                          'government_labels': batch[4]}  # 변경\n",
        "                if self.args.model_type != 'distilkobert':\n",
        "                    inputs['token_type_ids'] = batch[2]\n",
        "                outputs = self.model(**inputs)\n",
        "                loss, (politic_logits, government_logits)  = outputs[:2]\n",
        "\n",
        "\n",
        "                if self.args.gradient_accumulation_steps > 1:\n",
        "                    loss = loss / self.args.gradient_accumulation_steps\n",
        "                loss.backward()\n",
        "\n",
        "\n",
        "                # Politic\n",
        "                if politic_preds is None:\n",
        "                    politic_preds = politic_logits.detach().cpu().numpy()\n",
        "                    politic_out_label_ids = inputs['politic_labels'].detach().cpu().numpy()\n",
        "                else:\n",
        "                    politic_preds = np.append(politic_preds, politic_logits.detach().cpu().numpy(), axis=0)\n",
        "                    politic_out_label_ids = np.append(\n",
        "                        politic_out_label_ids, inputs['politic_labels'].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "                # Government\n",
        "                if government_preds is None:\n",
        "                    government_preds = government_logits.detach().cpu().numpy()\n",
        "                    government_out_label_ids = inputs['government_labels'].detach().cpu().numpy()\n",
        "                else:\n",
        "                    government_preds = np.append(government_preds, government_logits.detach().cpu().numpy(), axis=0)\n",
        "                    government_out_label_ids = np.append(\n",
        "                        government_out_label_ids, inputs['government_labels'].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "\n",
        "\n",
        "                # 배치별 loss 출력\n",
        "                tr_batch_loss += loss.mean().item()\n",
        "                tr_loss += loss.item()\n",
        "\n",
        "                if (step + 1) % self.args.gradient_accumulation_steps == 0:\n",
        "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.args.max_grad_norm)\n",
        "\n",
        "                    optimizer.step()\n",
        "                    scheduler.step()  # Update learning rate schedule\n",
        "                    self.model.zero_grad()\n",
        "                    global_step += 1\n",
        "\n",
        "            train_losses.append(tr_batch_loss/(step + 1))\n",
        "\n",
        "\n",
        "            # 정확도 계산\n",
        "            politic_preds = np.argmax(politic_preds, axis=1)\n",
        "            government_preds = np.argmax(government_preds, axis=1)\n",
        "\n",
        "            train_result = compute_metrics(politic_preds, government_preds, politic_out_label_ids, government_out_label_ids)  # 변경\n",
        "            train_accuracies.append(train_result[\"government_accuracy\"])\n",
        "\n",
        "\n",
        "            #평가\n",
        "            results = self.evaluate(\"dev\")\n",
        "\n",
        "            val_accuracies.append(results[\"government_accuracy\"])\n",
        "            val_f1_scores.append(results[\"government_f1_macro\"])\n",
        "            if results[\"government_accuracy\"] >= best_government_acc:  # Save best result based on accuracy ///  results[\"politic_accuracy\"] > best_politic_acc and\n",
        "                #   best_politic_acc = results[\"politic_accuracy\"]\n",
        "                best_government_acc = results[\"government_accuracy\"]\n",
        "\n",
        "                self.save_model()\n",
        "\n",
        "        return global_step, tr_loss / global_step\n",
        "\n",
        "    def evaluate(self, mode):\n",
        "        if mode == 'test':\n",
        "            dataset = self.test_dataset\n",
        "            trainer.load_model()\n",
        "        elif mode == 'dev':\n",
        "            dataset = self.dev_dataset\n",
        "        else:\n",
        "            raise Exception(\"Only dev and test dataset available\")\n",
        "\n",
        "        eval_sampler = SequentialSampler(dataset)\n",
        "        eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=self.args.eval_batch_size)\n",
        "\n",
        "        # Eval!\n",
        "        print(\"***** Running evaluation on %s dataset *****\", mode)\n",
        "        print(\"  Num examples = %d\", len(dataset))\n",
        "        print(\"  Batch size = %d\", self.args.eval_batch_size)\n",
        "        eval_loss = 0.0\n",
        "        nb_eval_steps = 0\n",
        "\n",
        "        politic_preds = None\n",
        "        politic_out_label_ids = None\n",
        "        government_preds = None\n",
        "        government_out_label_ids = None\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "            batch = tuple(t.to(self.device) for t in batch)\n",
        "            with torch.no_grad():\n",
        "                inputs = {'input_ids': batch[0],\n",
        "                          'attention_mask': batch[1],\n",
        "                          'politic_labels': batch[3],  # 변경\n",
        "                          'government_labels': batch[4]}  # 변경\n",
        "                if self.args.model_type != 'distilkobert':\n",
        "                    inputs['token_type_ids'] = batch[2]\n",
        "                outputs = self.model(**inputs)\n",
        "                tmp_eval_loss, (politic_logits, government_logits) = outputs[:2]  # 변경\n",
        "\n",
        "                eval_loss += tmp_eval_loss.mean().item()\n",
        "            nb_eval_steps += 1\n",
        "            # Politic\n",
        "            if politic_preds is None:\n",
        "                politic_preds = politic_logits.detach().cpu().numpy()\n",
        "                politic_out_label_ids = inputs['politic_labels'].detach().cpu().numpy()\n",
        "            else:\n",
        "                politic_preds = np.append(politic_preds, politic_logits.detach().cpu().numpy(), axis=0)\n",
        "                politic_out_label_ids = np.append(\n",
        "                    politic_out_label_ids, inputs['politic_labels'].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "            # Government\n",
        "            if government_preds is None:\n",
        "                government_preds = government_logits.detach().cpu().numpy()\n",
        "                government_out_label_ids = inputs['government_labels'].detach().cpu().numpy()\n",
        "            else:\n",
        "                government_preds = np.append(government_preds, government_logits.detach().cpu().numpy(), axis=0)\n",
        "                government_out_label_ids = np.append(\n",
        "                    government_out_label_ids, inputs['government_labels'].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "        eval_loss = eval_loss / nb_eval_steps\n",
        "        results = {\n",
        "            \"loss\": eval_loss\n",
        "        }\n",
        "\n",
        "        val_losses.append(eval_loss)\n",
        "        #예측 확률 중 가장 높은 거 1개, 2개 뽑기\n",
        "        top2_politic_preds = np.argsort(-politic_preds, axis=1)[:, :2]\n",
        "        top2_government_preds = np.argsort(-government_preds, axis=1)[:, :2]\n",
        "\n",
        "        politic_preds = np.argmax(politic_preds, axis=1)\n",
        "        government_preds = np.argmax(government_preds, axis=1)\n",
        "        result = compute_metrics(politic_preds, government_preds, politic_out_label_ids, government_out_label_ids)  # 변경\n",
        "        results.update(result)\n",
        "\n",
        "        top2_politic_accuracy = 0\n",
        "        top2_government_accuracy = 0\n",
        "        #top2 정확도\n",
        "        for i in range(len(government_out_label_ids)):\n",
        "            if government_out_label_ids[i] in top2_government_preds[i]:\n",
        "                top2_government_accuracy += 1\n",
        "\n",
        "        government_correct = [true_label in top_predictions for true_label, top_predictions in zip(government_out_label_ids, top2_government_preds)]\n",
        "\n",
        "        top2_government_accuracy /= len(government_out_label_ids)\n",
        "\n",
        "        #top2 f1\n",
        "        top2_government_f1 = f1_score(government_correct, [1] * len(government_correct))\n",
        "\n",
        "        print(\"***** Eval results *****\")\n",
        "        for key in sorted(results.keys()):\n",
        "            print(\"  %s = %s\", key, str(results[key]))\n",
        "        print(\"top2_government_accuracy :\", top2_government_accuracy)\n",
        "        print(\"top2_government_f1:\", top2_government_f1)\n",
        "\n",
        "        return {\"government_accuracy\" : results[\"government_accuracy\"],\n",
        "                \"government_weighted_f1\" : results[\"government_weighted_f1\"],\n",
        "                \"government_f1_macro\" : results[\"government_f1_macro\"],\n",
        "                \"government_abs_error_accuracy\" : results[\"government_abs_error_accuracy\"],\n",
        "                \"government_abs_error_f1\" : results[\"government_abs_error_f1\"]\n",
        "        #        \"government_absolute_errors\" : results[\"government_absolute_errors\"]\n",
        "                }\n",
        "\n",
        "    def save_model(self):\n",
        "        # Save model checkpoint (Overwrite)\n",
        "        if not os.path.exists(self.args.model_dir):\n",
        "            os.makedirs(self.args.model_dir)\n",
        "        model_to_save = self.model.module if hasattr(self.model, 'module') else self.model\n",
        "        model_to_save.save_pretrained(self.args.model_dir)\n",
        "        self.tokenizer.save_pretrained(self.args.model_dir)\n",
        "\n",
        "        # Save training arguments together with the trained model\n",
        "        torch.save(self.args, os.path.join(self.args.model_dir, 'training_args.bin'))\n",
        "        print(\"Saving model checkpoint to %s\", self.args.model_dir)\n",
        "\n",
        "    def load_model(self):\n",
        "        # Check whether model exists\n",
        "        if not os.path.exists(self.args.model_dir1):\n",
        "            raise Exception(\"Model doesn't exists! Train first!\")\n",
        "\n",
        "        self.config = self.config_class.from_pretrained(self.args.model_dir1)\n",
        "        self.model = self.model_class.from_pretrained(self.args.model_dir1,\n",
        "                                                      config=self.config,\n",
        "                                                      args=self.args,\n",
        "                                                      politic_label_lst=self.politic_label_lst,  # 변경\n",
        "                                                      government_label_lst=self.government_label_lst)  # 변경\n",
        "\n",
        "        self.model.to(self.device)\n",
        "        print(\"***** Model Loaded *****\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ae0d262ed111462eb55a98275be16fae",
            "cff43afefc604eeb989af330a214ae95",
            "b9da9433a172417d92d50fe5ab766efd",
            "a2ec15dce12745c4b6fefdcff8280892",
            "ac0b462045c34697924a56c0a0feffd5",
            "456724b5b4df49a7af483ae1a3f53bb4",
            "982e4b34860f495c9bb96d142b52cc48",
            "7c37268b73b041679f42600bdeb2cc1c",
            "9bbb1880feff40ddb80ac8f12d902139",
            "407035f207154d1db56c77d6fd07cebd",
            "266077c939d04b32aa4a7f1c71b37bc2",
            "2edc907a24be43b2ba6d5a0350358dff",
            "05719deebece40aea62b7137d525f973",
            "8a4f91b3d9904246905380db3398f412",
            "b0fdbd866ed44ae29e9ccd26c4cfc9c2",
            "26cd32f2f1ff42d69cd3e73aff1ee577",
            "266a7bcdde9f4ce4a1e7e75ddee91448",
            "f2c68254e69541b280d0c0384d9c2251",
            "7b6b841c4c4e4ab1a389f72d00320312",
            "ab28e35ca09741639abe71f368c263f7",
            "13b356df94ce48d6a80a5a203103cb71",
            "409ae11fbcc24feb8da697e3746f1fff",
            "0b935ff23894408abd361a494205d4b7",
            "4eb20a9ebd1a4645b8762a6087495684",
            "a540df310f0e481cbdef2166f2c11367",
            "e694315724dc4db9b4a2a87438ba9cd3",
            "f3a80b0a0a834335be30ede2e9d30852",
            "5cd72da1ee0b4994b7e9ef6c4d8e3e52",
            "8d44e3457737463a9e39de645301a248",
            "441b7da2e56c4666841cc2a8c6bcb092",
            "4ffb02815bcd4cc5ba1da6f09246238c",
            "968d158dc9d34fc6aeee820cc3c6dfe7",
            "5759a1a57845476daf35486cda13e396",
            "81f5ad3d801747499074068cbc6853e1",
            "443f78c8af4e4042b388bd3e994feb00",
            "34f2999555c84544909b4869f5fb7a25",
            "74fc649769ba42aba714dc6b60d9f33c",
            "b03950292cdd4bdc84127b179952e0ff",
            "c05d22c6c9df40e7b3d78355ca1f4c08",
            "e57065daff2c43999b232bf29ab4b965",
            "07540977725248f5bfd9fdfcab80f698",
            "f8615fbb64f8476f898fc910a54656cb",
            "28bcc6dccb4f44fdb90fd09335a356ba",
            "b65f025d132c41d4b1fb1f434823a33a"
          ]
        },
        "id": "MfTHIHn9b7f2",
        "outputId": "f722aa29-55a6-43f2-c4b5-d1f39ead20e0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/255k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae0d262ed111462eb55a98275be16fae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2edc907a24be43b2ba6d5a0350358dff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/487 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b935ff23894408abd361a494205d4b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating features from dataset file at %s \n",
            "LOOKING AT train.csv\n",
            "자체 핵무장론 펴는 남북대결주의자에 통일부 맡겨 신임 통일부 장관 후보자에 지명된 김영호 성신여대 정치외교학과 교수가 29일 인사청문회 준비 사무실이 마련된 서울 종로구 남북회담본부에 도착해 장관 후보자가 된 입장을 밝히고 있다. 연합뉴스윤석열 대통령이 29일 통일부 장관 후보자로 김영호(64) 성신여대 교수(정치외교학)를 지명하고, 통일부 차관으로는 외교부 출신인 문승현(59) 주태국(타이)대사를 기용하면서 통일부 장차관이 모두 외부 인사로 채워지게 됐다. 통일부 장차관이 모두 외부인으로 채워진 것은 김영삼 정부 때의 ‘권오기 장관, 김석우 차관’ 체제 이후 25년 만이다. 특히 김영호 후보자는 그동안 “김정은 정권 타도”를 주장하고 여러차례 자체 핵무장을 강조한 ‘남북대결주의자’라는 점에서, 대북·통일 정책을 펼쳐야 할 통일부를 형해화하는 인선이라는 지적이 나온다.김 후보자는 그동안 언론 기고와 유튜브 등을 통해 적대적 대북관을 내보이고, 자체 핵무장과 미국 전술핵 한반도 재배치를 주장해왔다. 그는 2019년 4월18일 인터넷 매체 <펜앤드마이크> 기고에서 “김정은 정권이 타도되고 북한 자유화가 이루어져서 남북한 정치체제가 ‘1체제’가 되었을 때 통일의 길이 비로소 열리게 된다”고 주장했다. 2018년 9월13일 같은 매체에 기고한 글에서는 “남북관계는 적대관계”라고 주장했다. 지난 2월20일 유튜브에서는 “미국은 한국에 전술핵무기를 재배치하는 것을 적극적으로 고려해야 되고 한국도 미국에 그런 요구를 강력하게 해야 될 시점”이라며 미국 전술핵의 한반도 재배치 필요성을 주장했다.“남북관계는 적대관계”라서 “김정은 정권 타도”로 통일의 길을 열어야 한다는 김 후보자의 주장은 ‘강압적 흡수통일론’으로 볼 수 있다. 이는 “흡수통일을 추구하지 않는다”는 윤석열 정부 공식 방침과 배치된다. 전술핵 재배치 주장 또한 정부 입장에 반한다. 권영세 통일부 장관은 지난해 10월 국회 국정감사에서 여권 일각에서 주장하는 전술핵 재배치에 대해 “정부 입장은 아니다. 찬성하지 않는다”고 말했다.윤 대통령은 노골적인 적대적 대북관을 지닌 김영호 후보자를 장관에 기용한 것에 더해, 주미대사관 정무공사 등을 지낸 정통 외교관 문승현 대사를 차관에 내정했다. 이는 윤 대통령이 통일부의 기능과 성격을 대대적으로 바꿔 사실상 ‘북한인권부’로 바꾸겠다는 신호라는 풀이가 나온다. 통일부가 그간 주도해온 남북 대화·교류보다는 국제사회와 함께 북한 인권 문제를 부각하면서 대북 압박에 주력할 것이라는 관측에서다. 윤 대통령은 이날 대통령실 통일비서관에 국내외 인권 문제를 연구한 김수경 한신대 교수(사회복지학)를 내정한 것으로 알려졌는데, 이 또한 같은 맥락으로 해석된다.양무진 북한대학원대학교 교수는 “대화와 협력을 통한 평화통일을 지향하는 통일부가 아니라 대립과 대결을 통해 흡수통일을 지향하는 ‘대결부’ 또는 ‘북한흡수부’의 출발을 알리는 인사”라고 평가했다.외부 출신 장차관을 맞이하는 통일부는 뒤숭숭한 분위기다. 한 직원은 “통일부에 업무와 접근 방식, 구성원의 마인드 등 조직 정체성을 완전히 바꾸라는 요구인 것 같다”고 <연합뉴스>에 말했다.김 후보자는 이날 기자들에게 “원칙을 갖고 북핵 문제 해결과 남북관계 개선을 위한 기반을 닦기 위해 노력하겠다”고 말했다. 그는 ‘북한 정권이 타도돼야 통일을 할 수 있다는 생각에는 변함이 없는가’라는 물음에 “일부에서는 그렇게 보도가 됐는데, 제가 쓴 글이 있으니까 글을 잘 읽어보시면 그 문맥을 잘 이해할 수 있을 것”이라고 했다. 또 ‘대북 강경파로 알려졌는데, 통일부 장관으로서 교류와 협력을 하는 역할을 잘 수행할 수 있겠는가’라는 질문에는 “우려에 대해서는 청문회 과정에서 자세하게 말씀드리도록 하겠다”고 답했다.신형철 기자 newiron@hani.co.kr\n",
            "국토부에 경찰 권한 준다? '건폭 때리기' 당정협의, 문제점은… 정부·여당이 윤석열 정부 출범 1년에 즈음해 국토교통부 공무원에게 수사권 등 특수사법경찰 권한을 주는 방안, 건설기계 운송 거부 제재 강화 방안 등을 입법화하겠다는 입장을 밝혔다. 타워크레인에 스마트 작업기록장치를 부착하는 방안도 추진된다. 노동계에서는 '건설노조 때리기'에 더욱 열을 올리려는 행보라며 반발이 나왔다. 건설현장 갈등의 주 원인인 불법 하도급 근절을 위한 근본적인 대책 마련에는 소홀하다는 지적도 이어졌다.국민의힘과 정부는 지난 11일 국회에서 민·당·정 협의회를 열고 '건설현장 정상화 5대 법안' 개정을 조속히 추진하겠다고 밝혔다. 입법 작업은 국토부, 고용노동부, 법무부의 지원 하에 진행된다.당일 국토부가 발표한 '건설현장 불법행위 근절 후속대책'을 보면, 5대 법안 중 가장 먼저 눈에 띄는 것은 법무부 소관인 사법경찰직무법 개정안이다. 국토부 공무원에게 특별사법경찰 권한을 부여해 건설현장의 불법행위를 직접 수사·단속할 수 있게 하겠다는 내용이다.국토부는 △ 건설기계를 이용한 공사방해, 부당금품 요구, 정당한 사유 없는 운송거부 제재를 명시하는 건설기계관리법 개정안 △ 불법하도급·부실시공에 대한 형사처벌·행정처분 강화와 징벌적 손해배상제 도입 및 임금체불 방지를 위한 대금지급시스템, 불법행위 신고포상제 등을 담은 건설산업기본법 개정안을 담당한다.국토부 자료에는 안전운행, 노무관리 등을 위해 타워크레인 스마트 작업기록장치 부착을 추진한다는 내용도 포함됐는데, 이는 공사방해, 운송거부 단속에도 활용될 가능성이 있다.고용노동부는 △ 채용강요 제재를 과태료에서 형벌로 강화하는 채용절차법 개정안 △ 노동조합의 노동자·사용자 권리 침해, 대체근로 및 사업장 점거 등과 관련한 제도 개편을 위한 노동조합법 개정안을 맡았다.이 중 사법경찰법·건설기계법 개정안과 건설산업법 개정안 일부, 노조법 개정안 일부는 여당 의원 입법 형식으로 이미 국회에 발의됐다. 국토부는 오는 8월까지 나머지 법안도 발의할 계획이라고 밝혔다.▲민주노총 양경수 위원장이 4일 오후 서울 종로구 서울대병원 장례식장에 마련된 민주노총 건설노조 강원지부 간부 양회동씨 빈소를 찾아 조문하고 있다. ⓒ연합뉴스이른바 '5대 법안'에 대해 건설노조는 즉각 반발 입장을 밝혔다. 건설노조는 11일 낸 입장문에서 \"대책 대부분이 건설사의 불법행위에는 상징적 선언과 도구적 차원의 제도 개선에 머무르는 반면, 노동자에 대한 제재는 생존권 파괴 수준의 조치를 구체적으로 담고 있다는 점에서 극히 비대칭적으로 구성돼 있다\"고 지적했다.이어 국토부가 대책 설명 뒤에 붙인 참고자료에서 월례비와 노조 전임비를 \"불법·부당 금품 수수 현황\"으로 분류한 데 대해서도 건설노조는 \"월례비의 원인인 위험한 편법 작업 요구는 놔둔 채 결과인 월례비 수수만 금지해서 월례비는 사라지지 않는다\"며 \"노동법상으로 보장된 근로시간 면제제도를 '노조 전임비 강요'로 전제한 후 전임비 전체를 불법인 양 서술하고 있다\"고 편향성을 지적했다.건설노조는 \"문제의 핵심은 불법하도급\"이라며 정부의 관련 대책에 대해 \"고용 문제에 어떤 언급도 없다는 점에서 아무 대책도 아니다. 불법하도급을 처벌할 제도와 밝혀낼 방법이 없어서 불법하도급이 수십 년 간 내려온 게 아니다. 노동자의 고용 문제를 풀 의지가 없었기 때문에 불법하도급이 끊이질 않았던 것\"이라고 강조했다.건설노조는 \"다시 한번 노동자-사용자-정부-전문가로 구성된 건설업 혁신을 위한 대화기구를 만들 것을 제안한다\"며 \"이 대책이 시행되고 나서 발생할 문제들은 불을 보듯 뻔하다. 문제가 걷잡을 수 없이 커지기 전에 대화와 소통을 통해 대안을 마련하자\"고 촉구했다.\n",
            "박대출 \"우주항공청법 표류 중…7대 우주강국 가는 길 막지 말라\"  박대출 국민의힘 정책위의장이 28일 오전 서울 여의도 국회에서 열린 유·보 관리체계 일원화 방안 관련 당·정협의회에서 발언을 하고 있다. 2023.7.28/뉴스1 © News1 임세영 기자박대출 국민의힘 정책위의장은 28일 더불어민주당을 향해 \"7대 우주강국으로 가는 길을 더이상 막지 말기 바란다\"며 우주항공청 설치의 근거가 되는 '우주항공청의 설치 및 운영에 관한 특별법'을 조속히 심사해 달라고 촉구했다.  박 정책위의장은 이날 국회에서 열린 원내대책회의에서 \"우주항공청 특별법이 거대 야당의 어처구니 없는 몽니에 걸려서 하염없이 표류 중\"이라며 \"세계 주요국들은 우주 선점을 위해 치열한 경쟁을 마다하지 않는데 대한민국 주요 미래먹거리인 우주항공산업이 야당에 발목 잡혀 있는 현실이 참담하기만 하다\"고 밝혔다.   박 정책위의장은 \"국민의힘은 특별법의 신속한 통과를 위해 민주당이 요구한 안건 조정 (요구)도 신속히 수용했다\"며 \"그럼에도 어제 안건조정위는 민주당 불참으로 열리지도 못했다\"고 말했다. 이어 \"우주항공산업 육성은 지난 대선 때 이재명 민주당 대표의 핵심 공약이었다\"면서 \"지난 5월 누리호 3차 발사 성공으로 우리나라는 우주 7대 강국으로 도약하는 계기를 마련했지만 우주선진국과 격차를 좁히려면 아직 갈 길이 멀고도 험하다\"고 했다. 그러면서 \"민주당은 지난 대선 때 국민들에게 드렸던 우주항공청 설립 약속을 지켜야 한다\"며 \"더이상 시간을 질질 끌지 말고 조속히 법안 심사에 나서주기 바란다\"고 민주당의 태도 변화를 촉구했다. 윤석열 정부 핵심 국정과제 중 하나인 우주항공청 설치는 과방위가 두 달 가까이 공회전하면서 법안 통과가 늦어지고 있다. 특별법은 전날 상임위에서 결론을 내지 못한 채 안건조정위원회로 회부됐으나, 안조위는 첫날부터 파행됐다. 민주당 안조위원들이 '다수당 소속 조정위원 중 위원장을 선출한다'는 국회법 제57조의2 5항에 따라 과방위 민주당 간사 조승래 의원을 위원장으로 추천했으나, 국민의힘은 조 의원 대신 변재일 민주당 의원을 추천한다는 입장을 밝히면서다.박 정책위의장은 또한 '서울-양평고속도로 노선 변경 관련 대통령 처가 특혜 의혹에 대한 진상규명을 위한 국정조사 요구서'를 민주당 소속 의원 전원 명의로 제출한 데 대해 \"답정너(답은 정해져 있으니 너는 대답만 해) 국조\"라며 철회를 요구했다. 그는 \"양평 고속도로 노선 변경 검토는 문재인 정부 때 이뤄졌음이 밝혀졌음에도 민주당은 어깃장 정치를 계속하고 있다\"고 비판했다. 이어 \"민주당이 답정너 국조를 벌인 이유는 너무 뻔하다. 8월 소환서를 물타기하는 국면 전환용 국조이고 이재명 대표 방탄이 목적인 것\"이라고 꼬집었다. 그러면서 \"민주당은 가짜뉴스 공장 문을 닫고 반대를 위한 반대, 이재명 방탄을 위한 국조 요구를 지금이라도 철회하기 바란다\"고 덧붙였다.\t\t\t\tangela0204@news1.kr                \t\t\t\n",
            "GDP 250조' 우크라 재건에 2000조?…전쟁 나라에서 尹의 민망한 '잿밥 외교' 대통령실이 우크라이나 재건사업 규모를 '2000조 원'으로 파악하고 있다는 보도들이 쏟아져 나오고 있다. 2000조 원은 한국의 1년 GDP에 해당하는 엄청난 규모다. 그중에 한국 몫은 66조 원이라고 한다.'2000조 원'이라는 규모의 출처는 명확하지도 않다. 지난 14일 <파이낸셜뉴스>가 \"대통령실은 우크라이나 재건 사업에 대해 '2000조 원 이상 규모의 공사와 경제 사업이 따를 것으로 추정된다'고 밝혔다\"고 보도했다. 한국 정부의 '몫'이 이 중 66조 원이라는 보도도 나왔다. 대통령실이 직접 '2000조 원'을 언급했다.이 매체는 원래 우크라이나 재건 사업이 최대 1조 달러(약 1270조 원) 이상으로 평가됐지만 \"2000조 원 이상으로 평가가치가 높아진 것을 놓고 대통령실 고위관계자는 '중장기적으로 보면 우크라이나가 스스로 산정하지 못한 장기적인 인프라 건설에 추가 소요가 발견될 수 있다'고 설명했다\"고 전했다.이번 순방을 계기로 대통령실 측이 우크라이나 재건 비용을 '2000조 원' 규모로 추산한 셈이다. 갑자기 700조 원 안팎이 훅 늘어났다.대통령실은 우크라이나 방문을 순방 중에 결정한 이유에 대해 '전후 재건 사업 참여'를 명분으로 내세우고 있다.<중앙일보>는 17일 \"윤 대통령의 재건 사업을 강조한 배경과 관련 대통령실 최상목 경제수석은 지난 14일 폴란드와 우크라이나 재건 협력 양해각서를 체결한 이후 기자들과 만나 '우크라이나는 전쟁 피해를 복구하는 리빌딩을 넘어, 국가 시스템을 업그레이드하는 뉴빌딩을 추진 중\"이라며 향후 재건 사업이 단순한 재건과 복구 수준을 넘어선 규모가 될 가능성을 시사했다\"고 전했다. 이 매체는 \"선진국들 역시 우크라이나 재건 사업이 제2차 세계대전 이후 미국이 유럽 16개국을 지원했던 '제2의 마셜플랜'이 될 가능성이 클 것으로 전망하고 있다\"고 보도하기도 했다.그런데 2000조 원 규모라는 건 대체 어디에서 나온 걸까.당초 '1조 달러'라는 수치는 우크라이나 정부 측이 제시한 안을 토대로 추정한 것으로 보인다. 앞서 <연합뉴스>는 두 달여 전인 지난 5월 22일 폴란드 바르샤바에서 개최된, 한국·폴란드·우크라이나 3국 민간 단체 주축의 '우크라이나 재건을 위한 국제콘퍼런스' 소식을 전하며 \"우크라이나 정부가 추정하는 재건사업 규모는 9000억 달러(약 1200조 원)에 달해 21세기판 마셜플랜으로 불린다\"고 전했다. 이건 '민간 단체'들이 '정부'를 인용해 낸 추산이다.두 달 만에 이번 윤석열 대통령 순방 도중 재건 사업 규모가 2000조 원으로 상승했다.먼저 이같은 규모의 재건 사업 비용이 어디에서 충당될 것이냐는 의문이 든다. 정부가 인용하는 '마셜플랜'은 미국이 전후 유럽 재건을 위해 130억 달러를 쏟아 부었던 사례를 말한다. 당시엔 현금과 현물을 쥔 미국이라는 확실한 자금 출처가 있었다. 미국은 서유럽 국가를 비롯한 20여개 국에 직접 돈을 댔다. 하지만 우크라이나 재건 사업은 결이 다르다. 유럽과 우크라이나 단일 국가, 규모도 비교 불가다. 자본주의 발전과 함께 유럽의 성장이 미국에 시장을 확보해 준 것처럼, 지금은 자본주의 고도화로 이행되는 기간도 아니다. 무엇보다 2000조 원을 누가 지불할지 알 수 없다.우크라이나 GDP는 전쟁 이전인 2021년 2000억 달러 수준이다. 약 253조 원이다. '재건 비용'은 우크라이나 GDP의 8배에 해당한다.한국 코트라에 따르면 2022년 우크라이나가 받은 해외 원조는 약 320억 달러이며, 그중 140억 달러가 무상원조다. 국방비 지출에 허덕이는 우크라이나의 총 수입은 600억 달러고, 총 지출은 832억 달러다. 코트라는 \"2023년 우크라이나 경제전망과 관련해서 국제기구나 우크라이나 정부 및 기관에서 내놓은 수치를 보면, 비교적 편차가 심한 편이다. 현재의 사태가 언제 끝날지 알 수 없는 상황으로 전망에 대한 의견도 분분한 것이라고 이해된다\"고 했다.실제 우크라이나 경제부는 2023년 GDP 성장률을 3.2%로 보고 있지만, 국제통화기금(IMF)은 1%로 보고 있다. 전쟁 수행 중인 국가이기 때문에 경제 전망이 들쭉날쭉다. 현재 우크라이나는 막대한 재정 적자를 주로 유럽과 미국의 해외 원조로 충당하고 있다.재건사업은 결국 '투자 유치'로 가능한데, 지급보증을 설 만한 곳은 마땅치 않다. 문제는 투자금 회수다. 우크라이나의 경제 규모가 애당초 크지 않고 농업 중심 산업이 발전했다는 것도 '투자 회수' 문제와 관련해 불투명성을 높인다. '중동 특수'에 빗대는데, 우크라이나는 '오일머니'를 가진 나라도 아니고, 지금 세계가 1970년대인 것도 아니다.돌이켜보면, 이명박 정부는 G20 정상회의에서 450조 원의 경제 효과가 있다고 했다.(G20이라는 조직 자체가 지금 유명무실하다.) 윤석열 정부 들어선 후 전경련 산하 연구원은 청와대 개방만 해도 2000억 원의 경제 효과가 있다고 했다. 그 돈은 지금 다 어디로 갔을까?'2000조 원'의 장빛 환상을 말하기엔 성급하다. '종전'도 안 한 나라에서 '2000조 원'을 찾는 '잿밥 외교'도 민망하기 그지없다.▲볼로디미르 젤렌스키 우크라이나 대통령이 15일(현지시간) 우크라이나 수도 키이우의 대통령 관저인 마린스키궁에서 열린 한-우크라이나 정상회담 공동 언론발표에서 윤석열 대통령의 발언을 경청하고 있다. ⓒ연합뉴스\n",
            "*** Example ***\n",
            "guid: train-0\n",
            "input_ids: 2 1114 688 29168 30177 3545 29950 1626 29963 30110 5817 29951 6566 9738 3785 6566 726 2086 29951 3315 30077 26856 25058 27940 1860 574 29956 782 29982 794 30133 28992 700 3018 29947 649 30077 188 6906 1626 30016 30233 10892 29951 2608 29973 726 2086 29956 73 729 29952 2294 29955 24 29948 5 13258 30425 30197 30194 308 29947 782 29982 6566 726 2086 29958 26856 36 2238 39 25058 574 36 27940 30073 39 17 3315 29959 29955 18 6566 2958 9563 29950 4700 1043 29972 128 30158 30091 36 2338 39 54 30204 29988 36 1494 39 1804 29965 6567 8738 29962 6566 20858 30023 29947 432 2227 794 29958 6579 29954 30007 163 29948 5 6566 20858 30023 29947 432 26186 9563 6579 30028 45 29961 7848 269 117 29953 96 12225 29960 726 18 9024 30035 2958 95 1529 378 509 30027 49 29947 29948 5 454 26856 2086 29950 1239 105 4801 1617 26409 106 17 572 29959 29955 766 30084 30385 1114 688 29168 29952 754 29957 96 1626 29963 30110 5817 95 232 217 29951 29962 18 12260 77 1710 520 29952 1978 30087 70 6566 29965 274 29973 30024 29959 29950 8856 29947 24545 722 29947 2120 5 118 2086 29950 1239 294 12488 30033 6946 55 29952 257 9648 30006 12260 30023 29952 5674 29947 29955 18 1114 688 29168 29990 247 5973 30467 2355 4342 30055 29965 572 29973 30376 29948 5 46 29950 7370 30027 88 30086 9920 29982 897 3132 240 3340 20875 10643 30169 536 12488 29951 29962 105 4801 1617 29947 26409 30078 29955 518 868 19664 19026 29962 8891 475 30083 29996 29956 96 23 30083 29996 95 16 75 30080 29952 117 1710 29953 3755 9315 1428 30007 179 106 15 572 29987 29948 5 3098 30027 161 30086 10973 29982 195 29961 3132 29951 12488 29957 576 29951 29962 29950 105 1626 13309 29950 9648 13309 106 225 572 29987 29948 5 136 28 30086 2145 29982 6946 29951 29962 29950 105 247 29961 131 29951 5973 30467 27411 29965 4342 30055 29959 29950 45 29952 969 30006 9563 1037 5885 75 29955 131 29967 247 29951 591 712 29965 1682 29959 30007 356 266 2300 106 336 30053 247 5973 30467 29953 2355 4342 30055 434 30004 29952 572 29987 29948 5 105 1626 13309 29950 9648 13309 106 7961 105 4801 1617 26409 106 33 1710 29953 489 29952 208 29986 30087 667 118 2086 29953 572 29961 96 18104 30006 4732 14721 30177 95 26 555 37 24 29948 5 6 29950 105 4732 14721 29952 3466 29959 29954 109 29950 29948 106 9 8072 30194 269 1089 1220 29990 1880 30077 29948 5 5973 30467 4342 30055 572 751 269 729 29951 28147 29948 5 10570 30042 6566 726 29961 136 29973 186 30086 586 1153 30111 29964 29951 29962 4462 4955 29951 29962 572 29959 29950 5973 30467 4342 30055 29951 275 105 269 729 29961 262 29948 5 3703 29959 29954 109 29950 29948 3\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "politic_label: 4\n",
            "government_label: 3\n",
            "*** Example ***\n",
            "guid: train-1\n",
            "input_ids: 2 8134 30501 365 41 494 2096 1038 29965 1184 29950 8774 29967 2269 434 41 8134 30501 4708 365 29947 676 29982 1602 7869 8424 2519 18959 29951 29962 40 11034 25335 6283 2501 798 451 40 355 2838 29965 208 29955 6749 29951 3188 29952 6825 24 29948 5 19916 30005 5 85 5 676 436 305 29968 1 12580 29968 19210 30197 214 19731 6819 3449 1557 6833 29972 8134 30501 365 36 1602 2270 30572 39 13 878 29982 494 30033 4446 30112 29958 6841 30024 30340 24 29950 3327 2148 1613 29965 2269 29959 29950 96 494 298 4446 30112 29953 5140 29951 1538 2148 4173 30031 29975 30043 95 10 237 30063 29953 27 2499 253 29948 5 13941 29961 1848 30027 88 30086 25400 30155 29990 3542 77 4446 30112 298 660 30112 29951 1538 2148 62 4446 30112 29951 1538 855 29952 1100 29957 45 9563 562 29953 1412 2096 29953 651 29952 1439 29959 29955 717 20369 30083 30032 29965 649 29959 29960 205 3314 29987 29948 5 463 1304 3407 566 36 1236 30245 30245 39 11 1309 9563 494 30033 4446 30112 203 29953 3085 29956 3461 5368 29955 1412 2096 29953 319 30006 20369 30083 30032 29956 7129 1439 29959 29954 821 29955 24 29986 1412 2096 29990 494 2096 29953 709 29951 1233 30076 30021 29956 75 29955 24 1312 281 29956 1191 30201 29948 5 118 365 29961 105 788 30006 9563 3851 29957 901 29956 22449 29955 24 29950 494 2096 29951 401 5140 30155 29947 5131 29952 575 29955 24 29948 106 94 105 901 29951 318 30007 3327 494 298 4446 30112 319 29952 785 30049 434 29956 24 29986 4173 30031 29975 30043 29952 5560 29987 29948 106 15 515 29987 29948 5 4173 30031 29975 30043 29953 1377 30038 30057 29961 1348 8927 298 4446 30112 29953 5140 29951 1538 2148 29952 494 29953 5140 29951 1538 2148 29958 14448 1348 8927 29953 2471 1316 1348 29947 29985 30024 30077 494 30033 4446 30112 20369 2269 55 29947 29948 5 118 365 29961 105 538 29953 5180 30194 30459 29951 29950 410 153 2389 29965 735 9563 14 131 8927 29956 24 30080 6571 331 29987 29948 106 94 105 334 4173 30031 29975 30043 29952 257 131 8927 29956 345 2389 29953 1038 29965 4832 29950 2494 12270 29956 266 37 24 29960 29965 601 29959 30053 28382 2395 30251 29948 106 15 103 29987 29948 5 423 30353 30330 2145 8419 290 370 29968 5 1466 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "politic_label: 2\n",
            "government_label: 0\n",
            "*** Example ***\n",
            "guid: train-2\n",
            "input_ids: 2 14553 105 25618 30018 8918 18 4616 29981 29950 1653 106 20 7359 105 2668 13309 29951 666 106 8072 30194 308 29990 1890 15883 30336 5486 18 20 7359 28598 30045 342 1198 30033 1890 20 7359 89 30238 5486 29956 610 29982 648 13128 1577 6928 2633 87 2458 25949 30336 30058 29969 25618 30018 29965 1310 22987 29959 29955 24 29948 5 436 196 8072 30194 308 29990 20 7359 28598 30045 342 1198 29956 610 29982 648 13128 1577 6928 2633 29951 24 29950 96 2458 25949 36 17278 1 39 5790 25618 30018 95 17 8918 29987 29948 5 334 8918 29951 29950 2458 25949 721 6119 29992 29967 295 27 29948 5 2668 833 29947 2458 25949 5790 25618 30018 29965 699 8918 29957 45 29961 1268 29947 29955 18 131 308 29953 8918 29967 604 29947 29948 5 17196 648 145 29966 1314 30071 30777 20 7359 1198 30033 20 7359 89 30238 5486 29956 25618 30018 242 29951 1185 2608 29973 695 308 29990 15883 30336 5486 29965 10529 29948 5 20 7359 1198 29950 2458 2350 29992 29952 3066 344 30385 29965 12 29960 29967 27 29948 5 695 308 4847 29950 23815 1141 30071 30777 2608 29973 20 7359 1198 4847 30033 794 29965 7243 29948 5 265 833 1946 29950 25618 30018 242 9563 1149 29973 22987 29959 29955 3664 29965 19831 186 30208 30067 29881 29987 29948 5 2458 25949 2350 29972 24291 29995 43 131 29985 30366 28737 29969 20294 9110 1557 825 29990 25949 28 2571 29972 218 30167 30045 10938 30151 23347 1232 30079 30074 36 252 30074 39 8599 55 186 30044 29967 295 8918 29987 29948 5 669 30066 833 4350 11987 29988 1859 9563 342 29952 800 62 29972 8072 30194 308 29990 1890 15883 30336 5486 18 20 7359 28598 30045 342 1198 30033 1890 20 7359 89 30238 5486 29956 610 29982 13128 1577 6928 2633 87 2458 25949 2350 25618 30018 29951 22987 29959 29955 24 29948 5 436 13258 8918 29965 3384 695 308 29990 20 7359 1198 29950 10857 29965 2569 29955 2350 29992 29952 3066 344 30385 29957 286 8443 833 30016 30233 1380 29984 9563 1149 29987 29948 5 695 308 29961 833 30016 30233 432 30063 30179 29951 29962 105 264 29956 295 8918 29957 45 29961 2458 25949 2350 29951 275 4728 29953 913 29952 27521 29990 1290 29951 1577 4906 1038 29965 700 29959 29960 396 20 7359 1198 29953 4616 24 29950 1653 9563 1863 30292 45 106 360 27 29948 5 20 7359 1198 29950 105 1935 29961 2668 289 29951 29962 29967 18 345 1577 29965 865 166 709 29959 29950 335 24 29986 29962 29967 666 29959 2499 369 1086 106 15 27 29948 5 2458 25949 5790 25618 30018 29950 2930 23047 55 9563 13128 29951 870 2883 10013 30027 25949 22255 29958 2630 30077 12482 28 29998 30030 104 29952 9807 29950 23744 29947 29948 5 5633 30027 29951 1577 2633 20483 29951 23744 29952 4181 3\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "politic_label: 2\n",
            "government_label: 4\n",
            "*** Example ***\n",
            "guid: train-3\n",
            "input_ids: 2 27470 105 433 1457 30084 29967 1779 29948 30153 514 18 3670 5231 109 29961 703 106 136 90 29982 98 30128 30173 21205 17076 29958 9804 30077 1903 5879 15457 30768 1809 30191 29976 15804 30084 29967 29951 29962 514 1212 12124 29963 464 55 29947 3375 30111 30102 29952 6825 24 29948 5 13258 16206 389 29982 640 29957 1903 2512 15457 1809 30191 66 29976 15804 30084 29967 9804 4048 30033 355 29973 514 29947 736 3113 974 1457 30084 29967 2675 2879 29965 1416 29959 29950 1323 29965 147 29955 29967 798 29951 3670 5231 29959 29954 109 29961 6236 29947 27470 7403 29951 29962 5471 30201 29948 5 514 29961 1239 451 1833 551 29951 29962 96 562 1809 30191 66 29976 15804 30084 29967 29956 888 18 66 29968 15804 30084 2169 5231 29987 29948 95 15 20053 55 29951 1010 29987 440 18 6 820 29967 4009 1010 29982 331 13937 437 45 9563 400 30201 29948 5 15297 29961 355 1421 29952 4408 29959 29960 396 738 10892 29965 15195 29960 29958 12 29950 55 1375 30006 29972 738 22341 29951 1678 29948 5 27470 29961 610 29982 105 36 7403 400 29965 257 39 7591 1323 642 991 551 29951 29962 3790 29957 23878 29956 1244 30201 29955 18 736 640 378 514 29953 1288 29994 30274 1833 551 29951 29962 14480 29951 4009 1010 30108 29954 4039 29948 106 94 17196 648 7237 29951 514 121 30044 29952 738 4241 29987 2499 253 29948 5 514 29947 136 389 29982 1922 145 29966 10189 30071 96 1809 30191 1457 30084 29967 2675 2879 95 17 1416 29959 29950 1323 29965 147 29955 29967 18 1809 30191 23 77 28 15804 30084 29967 62 1099 431 29951 29967 5231 29959 29954 109 30190 29952 331 13937 361 1312 45 29947 27470 1048 29947 29948 5 751 27470 29961 798 29951 5231 29959 29954 109 29961 514 29947 1546 30275 29972 7591 1323 991 907 29951 29950 5231 29957 467 29947 24 29950 45 5475 4009 6146 29987 29952 331 13937 437 45 9563 1010 24 29948 5 27470 464 29950 17196 240 4001 536 8 105 400 551 29951 29962 8883 29992 3128 29990 1014 55 29952 1201 30006 9563 645 29987 29952 117 18 514 29947 3670 798 29951 5231 29959 29954 109 30190 29952 331 13937 1355 284 29961 45 9563 1010 24 29948 106 15 103 29987 29948 5 892 514 29961 4048 562 18438 29956 798 29952 96 1457 30084 29967 95 225 29998 1958 29973 9804 736 29956 697 1809 30191 28 15804 30084 29967 29956 888 23 15804 30084 29967 715 9563 5231 29987 2499 2572 151 24 29948 5 215 1457 30084 29967 29950 343 4203 30150 3757 24 29948 5 27470 29958 628 738 4241 29965 147 29961 7237 29961 974 1421 55 29952 4408 29959 29960 205 5804 17380 29972 2512 5669 29951 738 10892 29965 723 29594 17196 253 29948 5 3360 29961 185 30057 29985 2512 5669 29984 29947 18 3\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "politic_label: 2\n",
            "government_label: 3\n",
            "*** Example ***\n",
            "guid: train-4\n",
            "input_ids: 2 21820 154 30475 23 29985 29947 4477 365 1783 1323 356 4268 1424 29952 2412 1783 1430 458 29951 664 29959 29950 2329 29947 586 8285 29965 11188 29989 1703 29987 29948 5 475 14931 9110 1557 36 50 30031 28464 39 9 635 29982 739 653 29965 208 29986 2412 6046 29953 1783 1430 458 29951 4268 1424 29967 1326 29950 599 29953 13182 2859 29952 3803 29987 29948 5 886 3980 1557 36 18981 30008 39 9 195 29961 192 2329 15935 29968 30021 30008 29965 208 29986 4268 1424 29952 2548 5260 1783 1323 458 29951 664 29959 29950 599 29953 5260 23249 30155 2859 29952 991 29987 29948 5 405 29953 30430 2486 29985 21820 10944 4367 11601 7450 55 365 3782 219 29982 648 235 2694 22924 3144 242 29951 29962 7915 29988 137 30021 30147 365 29953 59 7314 55 4268 8568 1423 1243 355 214 30016 30339 29952 6825 24 29948 5 17196 405 29953 30430 21820 10944 4367 11601 30074 29961 22924 3144 29951 29962 22580 29988 237 29958 628 3655 1010 29965 147 29950 29948 5 36 699 30321 30060 39 19916 30005 5 85 5 219 436 305 29968 3327 13182 29961 1164 3363 29952 2424 29959 29960 205 2412 9563 1795 30077 19 346 29982 2570 29951 998 18 1453 55 6038 29952 586 4285 15935 14206 1557 29951 1430 29959 30007 27 29950 30090 18 2859 29961 6 458 29951 21820 29990 195 29961 4268 1424 29967 664 29966 30655 29948 5 50 30031 28464 29950 191 10083 4303 29952 2794 29973 610 29963 4872 2412 3782 4268 1424 1423 3655 298 3226 6038 29952 606 148 103 30108 29954 4285 15935 14206 30008 29951 1430 29959 12173 27 29948 5 29145 50 30031 28464 29951 29962 3743 29952 257 96 4872 365 4268 1424 6731 11601 95 8 1817 45 29947 29948 5 50 30031 28464 23 30021 6779 29972 1138 14370 29974 365 29961 17196 214 29992 29990 1028 105 5849 85 30086 878 29982 30108 29954 29953 4268 1424 1423 77 3226 3655 29952 1323 29959 12173 27 29948 106 94 105 2683 9912 998 29961 19310 30349 77 97 30147 29952 10147 29973 1362 29998 29985 322 29998 1430 29959 30007 327 24 29950 30090 18 4268 1424 29961 11642 478 29947 583 154 30475 23 29985 29947 4477 4173 1323 29959 12173 27 29948 106 15 27 29948 5 1582 1910 6038 29947 2227 29951 596 30292 29954 1217 29950 10586 29948 5 4285 15935 14206 30008 29951 1430 29957 1783 6038 29953 596 1217 30033 2733 55 29961 586 30252 30633 9563 4343 30007 327 24 29950 30090 18 50 30031 28464 29951 29962 859 974 4231 3314 1183 29956 419 29253 29960 245 29947 29948 5 3266 4231 3314 29947 765 7431 22509 4872 365 29953 4268 1424 1423 6038 29961 5260 1783 596 29956 929 29954 29950 819 57 30086 29951 29993 596 30292 45 9563 835 5 4268 1424 6038 596 29965 396 3743 29947 7915 29988 365 29953 3\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "politic_label: 2\n",
            "government_label: 0\n",
            "Number of features: 4000\n",
            "Creating features from dataset file at %s \n",
            "LOOKING AT validate.csv\n",
            "조민, '총선 출마설' 기사에 \"피로감 느껴…의사 꿈 버리지 않아\" 조국 전 법무부장관 딸 조민 씨가 자신에게 제기되는 '총선 출마설'을 두고 선을 그었다.조 씨는 11일 자신의 SNS에 올린 입장문을 통해 \"저는 어려운 상황이지만 응급의학과 의사로 살고 싶은 꿈을 버리지 않고 의료봉사를 하고 있다”며 내년 총선에 출마하지 않는다는 입장을 분명히 했다.조 씨는 \"제가 내년 총선에 출마할 수 있다는 보도가 급격히 증가하는 것을 보았다”며 “저는 정치 입문에 대해 생각해 본 적도 없다. 이런 기사가 반복해서 나는 것에 피로감을 느낀다”고 밝혔다.그러면서 조 씨는 \"제 나름의 새로운 시도들을 하며 적극적인 삶을 만들어 가겠다\"고 덧붙였다.조 씨는 부산대 의학전문대학원 측의 입학취소 결정에 불복, '입학허가취소 처분 취소' 소송을 냈으나 지난달 6일 1심에서 기각당했다. 조 씨는 이에 불복해 항소했다.\n",
            "*** Example ***\n",
            "guid: dev-0\n",
            "input_ids: 2 17059 18 40 2103 2283 30118 40 1303 29951 41 18680 3199 1 1218 1283 2855 29954 109 29989 41 7306 43 4475 29984 30023 1587 17059 198 29956 404 29951 30007 1191 30078 29950 40 2103 2283 30118 40 10 26260 81 29952 46 30080 29948 5 71 198 29950 313 29982 404 29953 3251 29951 3421 729 30025 29952 257 41 174 29950 1655 451 1007 29998 4511 14091 1218 29958 326 29955 617 29961 1283 29952 2855 29954 109 29955 1178 14162 29965 6825 24 29948 106 94 819 2103 29951 2283 29959 29954 109 29950 1312 729 29952 4035 27 29948 5 71 198 29950 41 66 29956 819 2103 29951 2283 30049 37 24 1312 908 29956 6615 637 29959 29950 45 29952 48 30190 29948 106 94 105 174 29950 475 8818 29951 275 369 29973 270 25459 116 29948 5 547 1303 29956 2894 12078 60 29950 45 29951 18680 29952 8379 106 15 253 29948 5 2730 71 198 29950 41 66 5456 29953 717 1872 29992 29952 12 30053 969 30006 29972 1324 29952 429 29986 16 30251 29948 41 15 1363 29948 5 71 198 29950 14786 4643 10007 15533 457 29953 2631 30321 30021 564 29951 13554 18 40 2631 13553 30321 30021 2368 2915 40 1836 29952 1481 4430 136 30124 121 29982 23 30139 29951 29962 6913 30051 29987 29948 5 71 198 29950 26701 13554 29973 5493 29987 29948 5 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "politic_label: 1\n",
            "government_label: 0\n",
            "*** Example ***\n",
            "guid: dev-1\n",
            "input_ids: 2 8143 1353 13457 951 4425 30044 18 4329 147 29955 696 96 8143 5169 95 3484 29951 24 29950 14 8143 644 5 36 1303 599 29990 355 116 30148 39 436 12717 9580 3372 269 29953 797 16211 29990 19832 30058 1372 719 520 29951 19623 29973 3493 7615 29952 8905 1443 29956 5761 1039 29965 257 37 30266 169 645 30201 29948 5 19832 30058 1372 250 29990 355 29973 34 77 2550 55 972 29965 12 29950 1353 13457 29953 3764 29992 29961 1735 29959 30007 8143 250 29952 18990 13956 4329 29952 147 30190 29948 5 1372 495 2118 29952 3224 29960 205 269 29956 557 29957 96 1193 29490 95 250 29952 29145 5135 29957 1498 2606 29950 355 3406 29965 2839 29973 4329 1484 30200 29985 29952 3493 29959 30007 147 29961 45 9563 2850 29948 5 96 19832 30058 1372 250 557 4155 95 1039 29965 419 29959 29955 24 29950 5761 29961 19832 30058 1372 250 355 972 29965 6825 24 29950 1353 13457 150 30354 29953 3764 4425 30030 30044 29947 2253 9912 747 5203 29958 8143 250 29952 6825 24 29950 45 9563 645 30340 400 29959 29955 24 2499 497 29982 253 29948 5 10803 30033 3791 29953 19832 30058 1372 355 1353 13457 29992 29961 3764 29947 8143 250 29951 549 12078 29950 124 2454 1546 1505 18 1063 2227 250 29952 18719 29959 30103 30013 2550 29965 147 29989 30087 667 1546 1505 29952 485 29955 24 29948 5 19832 30058 1372 250 355 3900 30033 29953 1164 3363 29952 2424 29959 29960 1184 29948 5 416 4425 30030 30044 29961 547 1546 1505 29952 15800 29955 18 999 543 29951 2250 29954 109 29961 363 8143 250 29952 2253 5203 29993 9539 9563 35 446 45 29947 29948 5 334 29951 3465 30077 1353 13457 3764 62 29951 29950 1996 29952 28 30031 1298 286 1996 29952 257 709 5670 2635 30301 30534 36 16505 25859 39 544 29953 8143 250 29952 14 301 29967 24 30080 29948 5 731 6117 29969 29958 29962 332 29952 147 29952 37 24 29950 686 4150 29972 624 30301 30534 29953 678 30170 544 250 29952 6825 24 30080 30153 45 29947 29948 5 2006 29959 30007 19832 30058 1372 250 29990 355 30077 1353 13457 999 29972 301 29965 6510 29962 18 8143 250 355 972 29965 1907 29959 29950 11080 29951 24 29978 13956 8143 250 29952 731 30006 9563 2099 8345 18 98 14546 1546 527 29965 495 29973 7615 29952 8905 301 29967 645 30201 29948 5 14 1353 13457 29953 8143 250 355 972 1336 951 29961 8143 5106 29956 2231 30078 29950 14900 29953 3420 5670 29951 1538 1546 527 29965 495 29973 18 7407 5203 29958 1669 29951 2501 29965 2910 29957 286 8143 5106 29965 917 29973 481 8738 29962 950 29952 9251 29948 5 4393 563 29951 29962 29967 96 8143 4329 95 10 147 29960 205 3406 29965 7372 29957 301 29956 2918 2850 29948 5 3372 269 29950 3\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "politic_label: 4\n",
            "government_label: 2\n",
            "*** Example ***\n",
            "guid: dev-2\n",
            "input_ids: 2 14905 21960 41 742 30411 30168 55 4050 29100 506 8043 29958 1 2377 40 3016 26763 40 9 1537 29990 5631 41 4708 1537 4601 29956 2506 30006 1537 29953 506 5233 9563 4536 5107 742 30411 30168 642 55 5073 30027 378 140 999 365 29990 10652 29956 7308 30077 4050 77 2931 642 29952 10074 29960 29958 27 29948 5 29846 4050 642 29953 640 1600 29952 1310 842 30006 21106 29952 429 30251 1312 3858 29947 29948 5 9192 30010 1537 4601 825 29990 145 30044 29953 21960 29985 29992 29961 90 29982 648 586 29951 29962 23 30084 653 29951 29962 343 1394 30071 203 97 14546 653 29965 208 29955 742 30411 30168 281 29965 506 8043 29958 316 29960 29958 27 29948 5 118 825 29961 17196 97 14546 653 3177 157 214 29992 29990 1028 41 21960 29956 896 30007 14 4536 5107 742 30411 30168 642 29990 36 7915 29988 365 29953 39 21820 36 4268 30024 30474 39 642 62 742 30411 30168 642 29947 5884 29953 281 29972 45 195 29948 41 94 41 1031 30006 9563 742 30411 30168 281 29965 8043 29958 316 30190 29948 41 15 103 29987 29948 5 46 29950 41 1031 30006 9563 742 30411 30168 281 29965 12306 75 29954 109 30341 30457 5 4367 11601 30008 29965 917 29959 29969 29950 22312 1339 29948 41 15 27 29948 5 46 29950 626 36 737 39 738 29956 419 30201 29950 30090 738 29997 29948 264 29956 166 398 30049 331 13937 24 26156 180 653 30111 29947 24 30080 440 3580 4367 11601 29965 1769 30006 9563 6825 18 166 666 29957 45 29961 547 32 29947 6632 29959 29954 109 12173 356 21268 30108 1148 547 281 29956 640 29987 2673 281 640 1600 29952 1010 1227 29951 547 1180 29953 642 3782 24 30080 26156 29951 180 411 29992 18 1138 29947 2066 10616 29952 398 429 29986 29962 27 26156 591 45 29992 29952 645 29973 4249 1393 73 842 30006 6542 30043 29947 3033 45 195 29948 41 15 2721 29965 515 29987 29948 5 12183 355 29973 1899 29952 761 29961 7915 30336 21960 29985 29961 41 21960 29956 1114 30006 9563 4367 11601 29965 12 30251 1312 45 29947 262 29991 140 29951 4367 11601 29965 712 29959 30251 1312 831 41 225 240 4296 3122 536 42 14 1692 29951 29962 20872 515 29987 29948 5 118 825 29961 17196 506 653 432 30063 30179 29951 29962 1537 29953 4853 30115 9563 40 4285 1652 40 10 1272 29987 4430 18 17594 140 237 29953 3016 5136 281 29950 21960 1183 29951 29962 1376 29966 30254 29960 29958 27 29948 5 118 825 29961 41 5467 24730 29950 3016 5136 29950 626 3016 1048 784 29958 22048 45 41 336 30053 41 46 281 29965 4768 29956 507 30049 621 29950 116 29952 45 195 29955 1138 29953 842 30006 6542 77 1537 2031 30033 3016 5136 29950 5631 29957 784 29991 29955 369 3\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "politic_label: 1\n",
            "government_label: 0\n",
            "*** Example ***\n",
            "guid: dev-3\n",
            "input_ids: 2 20264 18 40 19197 14603 40 8712 30177 1225 29951 41 8078 1099 855 29947 471 31002 29972 29956 41 20264 11835 726 29947 815 4582 29969 19197 14603 8712 30177 12040 29951 180 404 29953 1530 29990 355 18 1780 29953 2189 712 29965 9761 29987 29948 5 72 726 29961 219 29982 586 29951 29962 214 29992 29990 1028 40 19197 14603 30118 355 3386 576 29951 275 1780 29951 29962 2744 77 2189 712 29956 2120 40 9 1483 29951 41 66 29956 3251 29951 3421 576 29952 4949 1629 30080 4716 591 572 29952 70 37 116 29948 41 94 41 8078 1099 855 29947 471 31002 29947 29955 281 29956 2454 45 29972 29954 174 29967 24110 6825 1629 29986 30631 440 3961 6330 591 599 1114 29956 116 29948 41 15 103 29987 29948 5 72 726 29961 41 5024 5813 684 29953 1629 29960 29998 12 22432 29967 1830 2378 29956 116 29950 591 45 29947 6541 29957 30090 11882 485 29955 404 3782 405 29992 29958 628 17103 29951 11433 1805 29952 2704 29960 205 174 29965 14272 29955 911 29959 29950 45 29951 275 13063 5247 17178 41 336 30053 41 6249 4248 29958 14 818 831 29967 893 29956 116 29948 41 15 253 29948 5 892 72 726 29961 136 30124 550 29982 3386 29951 815 4582 29969 265 30016 30015 198 29953 19197 29952 798 29951 24 30153 815 14111 3374 29956 14603 29987 1312 240 12717 536 908 29951 22 30597 41 467 29947 29991 30013 5931 2417 30006 29972 32 41 336 30053 41 787 29954 109 29960 29965 1991 440 18 24110 2617 29953 3297 29952 3366 29953 4999 9563 495 29959 30103 27 30153 45 29961 9583 3526 29947 38 29954 109 29952 37 116 29948 41 15 3040 29948 5 974 1303 29950 19197 798 29951 24 30080 30153 433 214 29953 5079 55 9563 4646 30201 29948 5 8145 14261 365 29961 136 497 29982 586 349 784 22 3248 30221 30025 29951 29962 41 72 726 29961 2982 726 30140 29952 6944 29964 30472 25193 29991 41 15 2188 29959 30053 41 1810 265 30016 30015 2393 29953 3297 29952 1287 19197 29947 29991 29955 369 6202 41 225 228 30080 29948 5 72 726 29961 41 174 29950 787 30007 572 29957 151 116 29948 41 94 41 798 29951 24 30080 30153 36 12869 29972 39 8599 29947 23 30071 2983 2290 30065 30023 29957 1262 29951 275 3526 29947 807 45 29952 66 5456 733 5766 29955 10818 30251 2499 692 1296 29957 45 41 360 572 29987 29948 5 578 72 726 29961 3342 22204 966 29990 355 17594 4708 237 29956 17196 586 5178 10130 237 3222 29951 29962 41 1353 29951 2858 721 696 30009 29996 1231 29958 1722 2910 18 5377 29975 30059 842 29956 434 29959 29948 41 15 14 335 275 41 137 30230 30138 29957 572 29952 6825 24 29948 41 94 41 476 822 29947 24545 169 3342 22204 30033 3\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "politic_label: 3\n",
            "government_label: 4\n",
            "*** Example ***\n",
            "guid: dev-4\n",
            "input_ids: 2 17594 18 19631 29951 41 5832 30078 29954 109 30007 3368 30124 29991 41 1 19631 41 10731 29957 1537 434 41 4708 17594 237 30033 19631 43 237 29956 713 29982 2582 29951 598 8395 30016 30015 29951 29962 1379 1337 29952 6825 24 29948 5 36 4708 558 39 19916 30005 5 145 5 713 436 305 29968 1 12580 29968 25220 30056 214 29947 30060 30044 4708 237 29950 713 29982 19631 43 237 29951 30007 41 2103 1087 29965 1184 29950 140 29953 14827 29947 390 666 29959 29955 140 29947 5832 30078 29954 109 12173 398 1542 29955 16 29950 58 434 29959 29948 5 613 3368 30124 29991 41 15 1416 29987 29948 5 6 43 237 29950 26701 41 1138 29953 1537 29961 4691 30004 29990 3030 29965 1340 29959 29950 335 29962 392 5885 82 5 538 1138 29961 925 29953 30102 29952 11137 6825 29846 5832 29953 2739 29965 4468 1633 5885 82 41 15 906 29987 29948 5 6 237 30033 6 43 237 29950 17196 546 188 6906 29953 14 5700 29951 29962 215 297 559 8395 29952 295 12 30053 6 30228 29961 1465 29965 7243 2499 218 30582 30158 1785 29963 17626 29961 885 29948 5 6 43 237 29950 751 41 1138 29952 6251 29953 707 29958 429 29960 6042 10731 29957 1537 29947 434 29959 30053 1537 29952 257 14827 29959 29955 405 29953 1982 29965 548 17101 30087 82 41 4825 1363 29948 5 3140 265 30364 29961 41 8072 30194 269 29953 15384 30033 1281 8020 29952 577 29960 205 1138 29947 2103 29951 29962 1087 5885 82 5 8072 30194 308 29961 405 29953 1324 9912 476 29953 1038 29951 275 1830 683 29947 116 29948 41 94 269 30033 2592 29951 180 1225 29951 29950 7982 29965 2158 29987 2499 82 5 751 819 2103 29951 29962 1087 29959 29950 58 405 29952 396 1138 29953 837 30006 11069 29947 24545 30090 964 29952 990 27 2499 218 1785 29963 17626 29961 253 29948 5 3140 6 237 29950 6 43 237 29953 3802 29952 4344 29959 29950 893 29951 29962 1797 28805 29952 1388 29959 30053 41 25473 4139 30797 30341 30457 5 1198 30277 29962 600 29951 500 613 608 30797 29950 30090 1393 1039 794 29967 254 30061 30390 29948 41 15 794 29965 11551 29955 18 6 43 237 29950 41 1239 140 29952 4832 29966 30341 29991 13101 204 29978 30797 29948 41 15 11975 29987 29948 5 9557 30052 30361 9602 30114 290 370 29968 5 1466 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "politic_label: 1\n",
            "government_label: 0\n",
            "Number of features: 500\n",
            "Creating features from dataset file at %s \n",
            "LOOKING AT test.csv\n",
            "민주당 \"윤석열 정부의 정치생명, 원희룡 입에 달려있다\" 더불어민주당이 '양평 고속도로 백지화' 관련 원희룡 장관에게 \"가짜뉴스 유포 그만하고 사전에 사업 백지화를 재가 받았는지 밝히라\"고 촉구했다.강선우 민주당 대변인은 7일 서면브리핑에서 \"원희룡 장관이 지금 해야 할 일은 서울-양평 고속도로 종점 변경을 둘러싸고 꼬리를 무는 의문에 답하는 것\"이라며 이 같이 밝혔다.그는 \"원희룡 장관이 라디오에 출연해 '민주당이 먼저 발표된 노선대로의 변경을 요청했다'며 우리 당 최재관 지역위원장, 정동균 당시 양평군수에게 책임을 덮어씌웠다\"면서 \"이는 새빨간 거짓말이다. 주무장관이라는 사람이 국책 사업에 대해서 사실도 확인하지 않고 가짜뉴스를 유포하고 있으니 어처구니없다\"고 주장했다.그는 \"팩트를 알려드리겠다. 2년 전에는 변경안 자체가 없었다. 그리고 당시 당정협의를 거쳐 설치하고자 했던 나들목은 강하면 방면이었다\"면서 \"입을 열 때마다 하나같이 가짜뉴스로 국민을 선동하고 있으니 이쯤되면 국토교통부 장관이 아니라 국민선동부 장관 아닌가. 원희룡 장관, 혹시 롤모델이 괴벨스인가\"라고 반문했다.그는 \"사업 백지화에 비판이 쏟아지니 백지화의 책임을 민주당에 덮어씌우려는 원희룡 장관의 나름의 기만술은 처량하고 한심하다\"며 \"원희룡 장관은 가짜뉴스 유포 그만하고, 사전에 사업 백지화를 윤석열 대통령에게 재가 받았는지나 밝혀라\"라고 촉구했다.그는 \"원희룡 장관이 판돈으로 건 것은 자신의 정치생명으로 그치지 않을 것\"이라며 \"윤석열 정부의 정치생명이 원희룡 장관의 입에 달렸음을 명심하고 성실하게 답하라\"고 촉구했다.\n",
            "*** Example ***\n",
            "guid: test-0\n",
            "input_ids: 2 1138 41 8072 30194 269 29953 475 4067 18 20264 165 29951 3432 29981 29948 41 4708 29947 40 10691 4739 7664 30024 40 355 20264 726 29951 30007 41 6534 2508 8616 2121 29959 29955 1590 29951 250 7664 30024 29965 20119 147 30190 26156 2294 29991 41 15 2188 29987 29948 5 126 30014 30035 1138 1899 29961 145 29982 8343 17422 29951 29962 41 20264 726 29947 538 356 70 32 29961 188 153 10691 4739 29196 1873 29952 5861 29955 6310 29965 137 29950 3526 29951 906 29959 29950 45 41 336 30053 6 990 253 29948 5 46 29950 41 20264 726 29947 3339 29951 934 29973 40 1138 29947 1185 524 30077 2594 733 29953 1873 29952 1416 29987 29948 40 94 264 140 10249 30023 246 6779 18 6799 30426 562 18102 29974 29951 30007 822 29952 4585 29986 31317 30608 29948 41 193 41 6 29950 234 30668 30067 5814 29947 29948 5 10443 29984 30023 29947 24545 258 29947 10343 250 29951 946 467 29967 645 29959 29954 109 29955 6534 2508 29965 8616 29959 29955 24 29978 30041 18503 30119 29948 41 15 572 29987 29948 5 46 29950 41 15667 29965 641 3008 30251 29948 5 28 30027 43 29951 29950 1873 30043 1114 29956 116 30080 29948 5 830 562 10159 28275 29965 1478 917 29959 29955 29969 27 30153 15576 29961 2520 30013 10378 29947 30080 29948 41 193 41 165 29952 208 117 11174 19428 6534 2508 29958 405 29952 8093 29959 29955 24 29978 30041 29768 30078 30013 11835 726 29947 262 29991 405 30014 17601 726 3498 5 20264 726 18 6284 27046 29947 2209 30651 29980 29972 29956 41 225 10382 29987 29948 5 46 29950 41 250 7664 30024 29951 1225 29947 18898 29954 30041 7664 30024 29953 822 29952 1138 29951 4585 29986 31317 30035 30103 29950 20264 726 29953 5456 29953 19602 30240 29961 206 30293 29959 29955 19309 29959 29948 41 94 41 20264 726 29961 6534 2508 8616 2121 29959 29955 18 1590 29951 250 7664 30024 29965 8072 30194 308 29951 30007 20119 147 30190 26156 29993 1789 29991 41 225 2188 29987 29948 5 46 29950 41 20264 726 29947 273 30475 9563 169 45 29961 404 29953 475 4067 9563 4864 29954 109 29952 45 41 336 30053 41 8072 30194 269 29953 475 4067 29947 20264 726 29953 165 29951 7912 30148 29952 15575 29959 29955 5276 29959 30007 906 11903 41 15 2188 29987 29948 5 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "politic_label: 0\n",
            "government_label: 1\n",
            "*** Example ***\n",
            "guid: test-1\n",
            "input_ids: 2 279 18520 282 518 1746 29994 41 8947 18 52 30864 30006 8207 30014 30299 29957 45 1 51 29974 29992 29951 2787 41 36 4069 874 5571 152 305 29968 39 152 1014 13697 5 279 417 29951 29962 29998 426 29956 30218 5 4342 30143 1812 5 9580 1812 5 17555 1165 2403 17341 6246 2513 1741 8403 30361 25363 2568 13322 5 27591 6438 7504 30435 19881 10379 30280 8899 18640 282 13236 19629 17056 290 370 29968 5 1466 7817 30104 30520 8899 30163 30005 290 370 29968 5 1466 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "politic_label: 0\n",
            "government_label: 0\n",
            "*** Example ***\n",
            "guid: test-2\n",
            "input_ids: 2 20091 30101 18 695 308 40 9553 40 8 41 21198 30975 30037 29951 29962 3033 831 1 2726 547 308 24 30080 29993 41 20091 30101 339 25746 21858 23595 29956 8072 30194 308 29953 131 10278 19719 2833 29995 30027 8371 9553 29965 26260 41 12428 29993 21198 30975 30037 29953 165 29951 29962 3033 11769 831 41 225 2520 30007 1225 29987 29948 5 20091 30101 574 29950 713 29982 13018 29991 1391 29951 934 29973 41 36 9553 29965 1593 29950 1943 39 174 29950 15036 29952 27 29948 5 308 29947 28887 30013 124 179 41 94 6 990 103 29987 29948 5 695 308 29961 17196 188 15106 6211 29951 29962 598 131 10278 19719 5361 2833 29995 30027 8371 29951 960 29973 41 5174 30077 837 29953 30102 18 137 30230 30138 29957 476 30023 29952 1647 171 14228 1874 29992 29961 518 3499 30209 30074 29951 275 2302 7960 2829 29965 21536 30124 29991 29955 4245 30021 29959 29955 18 2302 29964 29965 5067 29959 29950 5227 21208 29952 1506 24486 29955 8402 29948 41 15 103 29987 29948 5 141 574 29950 41 21763 384 29951 29962 29950 7091 29961 1594 30049 37 30484 29951 116 29948 41 94 41 1333 672 29965 476 29975 30083 30004 29952 1735 29959 29950 52 18 26805 28535 18889 23409 29955 24 29948 5 1935 29947 3430 10669 30006 1627 29972 29956 41 225 10382 29987 29948 5 141 574 29950 41 87 29956 48 30013 1281 29953 10669 30033 3030 29965 3636 29987 30153 46 258 29992 29953 1627 29947 547 45 41 336 30053 41 2730 21763 29953 3256 30004 29952 14621 2499 315 29950 30090 8078 21763 29956 15174 308 29947 18529 24 26156 2768 29980 30414 29948 41 15 6796 30080 29948 5 2730 141 574 29950 41 12260 29996 30060 2022 29991 15508 547 45 29947 518 29952 7088 29950 45 29947 262 29991 518 29953 688 3103 29952 3362 29959 29960 396 928 29953 15240 1018 29956 163 30153 45 41 336 13956 751 41 5227 21208 29952 772 692 7186 29964 29956 5067 30078 29950 45 29967 3796 27383 467 29990 1695 29948 5 538 5174 18 6911 30169 305 29965 308 29947 1294 5590 29955 24 29948 41 15 1225 29987 29948 5 141 574 29950 41 2265 29962 538 247 29951 29962 29967 1351 30044 29953 365 29947 1577 18339 29952 1481 29948 5 46 124 29951 538 5227 21208 29947 525 24 29948 5 591 22312 538 3284 24 29950 45 29947 29948 41 482 41 1333 1935 29952 1018 29959 30007 75 30013 40 171 14228 28535 29948 40 18889 17968 29947 29950 127 18 308 29947 405 29952 1100 5885 75 29950 30090 7038 28559 5307 1365 29952 538 2099 29955 24 29948 5 2506 29951 1390 29962 5 10943 2577 29959 26156 1464 30251 5 2726 547 308 29947 24 30080 29950 29956 41 225 10382 29987 29948 5 3 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "politic_label: 0\n",
            "government_label: 1\n",
            "*** Example ***\n",
            "guid: test-3\n",
            "input_ids: 2 342 15293 29995 30251 1312 8072 30194 18 1117 30144 29950 342 18 46 621 29950 420 41 2668 29961 6142 2316 29951 295 3095 30340 29981 29948 5 46 1099 117 29997 29948 2071 5746 29947 666 29957 451 29947 29948 5 830 3492 1694 29961 2119 131 29990 247 29953 6849 203 29953 5522 29958 1134 30077 599 29947 29948 5 7515 342 29953 549 29965 3860 29959 29954 29950 109 29950 29948 5 41 8072 30194 308 29947 20 7359 28598 30045 342 1198 30033 145 29982 4331 308 30069 29951 29962 833 30016 30233 29952 3384 286 1647 699 2102 30016 30339 29951 29962 14 103 29947 29948 5 3492 1694 2964 29951 29962 2964 30077 8947 688 28275 1242 36 4501 30346 39 8 342 29967 549 30049 37 24 1312 2721 29953 1530 29947 29948 5 26701 275 20 7359 1198 29950 688 28275 1242 549 29951 946 29950 1958 29952 3749 13956 98 29982 30067 29951 29967 41 28 1869 28 29965 664 29957 2548 30192 1361 29965 1696 32 30046 203 29953 2583 30200 29996 756 29965 396 2622 41 6 24 2499 754 29987 29948 5 41 765 12078 32 30046 18 32 29957 18 32 29957 30046 203 29951 29962 17165 5810 29973 2229 369 41 360 24849 13956 29967 8947 688 28275 1242 29951 549 29951 29950 1117 29965 215 29950 703 29957 579 29952 4630 1721 29947 29948 5 695 308 29967 754 29957 45 5475 342 29967 6142 4825 30024 29951 437 2316 29952 2234 29955 24 29948 5 1333 1148 342 29961 688 28275 1242 549 29951 4076 29957 2604 29965 646 29950 45 29982 30108 420 26701 180 906 29961 97 30467 57 29985 30633 29990 247 29953 2071 2462 29951 180 5351 29951 29962 443 29952 37 24 29948 5 12183 355 29973 136 30124 14945 8947 29975 27449 30233 29952 4253 29973 688 30012 30039 281 29956 40 4212 6461 40 33 3425 30078 29969 342 87 29951 29962 29967 437 683 1238 29958 7196 29948 5 7295 14716 29966 10434 30040 29964 342 26697 29961 713 29982 342 269 29953 729 29952 4035 253 29948 5 41 688 30012 30039 29951 946 29950 40 97 30467 57 29985 30633 40 42 29953 289 245 29951 1008 30078 29954 109 29950 29948 41 94 41 342 269 29958 30014 1183 30049 369 29947 116 29948 41 15 8313 103 29957 45 29947 29948 5 97 30467 57 29985 30633 29961 342 29947 40 688 27411 29965 1517 29959 17857 18 1423 29959 17857 18 11246 29959 17857 109 29950 29948 40 9 45 29952 893 1086 5 1333 8947 3492 1694 29951 29950 247 29953 688 26438 30519 29974 30187 36 7599 30255 30388 39 11 20 30276 55 688 924 1424 29953 3153 29967 4614 24 29948 5 342 29947 1006 29951 549 30049 301 97 30467 57 29985 30633 29947 3573 30292 37 24 29950 1721 29947 29948 5 97 30467 57 29985 30633 29952 754 29973 30259 20 7359 1617 3\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "politic_label: 0\n",
            "government_label: 1\n",
            "*** Example ***\n",
            "guid: test-4\n",
            "input_ids: 2 20091 30101 41 21194 30044 1002 30080 29950 30090 18 3818 6913 30201 29978 30041 2189 29973 29991 420 5500 30686 29967 24775 29948 41 20091 30101 339 25746 21858 23595 29956 13242 13316 726 29953 24331 29947 6913 30077 45 29952 26260 41 6913 30292 45 29952 227 30190 440 18 4102 29953 2751 30006 21653 41 283 2499 515 29987 29948 5 141 574 29950 702 29982 13018 3339 240 20885 29953 13926 11236 536 8 934 29973 41 36 15766 4048 29958 39 21194 30044 29947 1002 30080 29950 30090 18 1077 29967 822 29952 124 1335 29948 41 193 6 990 103 29987 29948 5 46 29950 41 2726 650 308 29961 1206 4048 29956 1181 29952 117 7 2189 29965 27 29948 41 94 41 736 192 117 11174 13316 726 29952 7290 30087 75 30341 30457 36 225 463 39 174 29950 18889 1206 29964 29955 29956 192 117 11174 7290 30087 179 36 15 369 1086 39 41 15 572 29987 29948 5 46 29950 46 621 29965 26260 41 242 9563 547 736 29956 3544 18 2387 2853 29950 32 29972 29956 5 21194 30044 29947 311 29995 29963 30503 29951 1002 29950 32 29947 420 41 3826 41 547 1206 736 29956 6169 29978 30013 4639 822 29952 7185 12 29950 30090 40 736 29956 192 117 11174 36 2189 5885 12 30341 30457 39 40 46 103 29952 25473 787 30007 5158 30007 17843 29952 37 24 26156 18 726 29947 24545 258 29947 18 308 29947 24545 258 29947 18 1164 29956 124 4104 41 15 722 29987 29948 5 46 29950 41 547 137 30230 30138 29951 405 29992 29961 4158 29959 29950 45 41 336 13956 41 405 29992 29967 10538 29951 14493 6913 30292 127 5458 30141 5944 5 3450 29951 29967 17658 29987 30153 169 36 13242 726 29947 39 2744 11903 29950 30090 124 20798 109 30190 29993 5 405 3782 70 37 24 29950 1140 1262 29950 15888 36 3818 39 1095 116 30080 29948 41 15 515 29987 29948 5 46 29950 41 1333 4334 6913 30201 29978 30041 221 9563 2189 29965 12851 420 547 127 48 30013 40 51 30098 29959 29984 29967 89 30071 29974 40 232 369 29947 4233 5 25473 6 258 29992 18889 5500 30686 29947 12206 30149 21032 24 29950 29956 18 3430 13086 258 29992 29951 30007 405 29953 674 29990 1737 29952 9738 29967 75 29950 29956 41 482 41 4158 30111 30040 30135 4233 41 225 253 29948 5 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "politic_label: 0\n",
            "government_label: 1\n",
            "Number of features: 500\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81f5ad3d801747499074068cbc6853e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForPoliticClassification were not initialized from the model checkpoint at monologg/koelectra-base-v2-discriminator and are newly initialized: ['politic_classifier.classifier.bias', 'politic_classifier.classifier.weight', 'government_classifier.classifier.weight', 'government_classifier.classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "set_seed(args)\n",
        "\n",
        "tokenizer = load_tokenizer(args)\n",
        "train_dataset = load_examples(args, tokenizer, mode=\"train\")  # label_types 인자 제거\n",
        "dev_dataset = load_examples(args, tokenizer, mode=\"dev\")  # label_types 인자 제거\n",
        "test_dataset = load_examples(args, tokenizer, mode=\"test\")  # label_types 인자 제거\n",
        "trainer = Trainer(args, tokenizer, train_dataset, dev_dataset, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GaOJN_2jxpF",
        "outputId": "7ec63f1a-1893-42e7-ab6b-ea1307f5d4f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Running training *****\n",
            "  Num examples = %d 4000\n",
            "  Num Epochs = %d 20.0\n",
            "  Total train batch size = %d 16\n",
            "  Gradient Accumulation steps = %d 1\n",
            "  Total optimization steps = %d 5000.0\n",
            "  Logging steps = %d 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   5%|▌         | 1/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch:  1"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Iteration:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0%|          | 1/250 [00:04<19:39,  4.74s/it]\u001b[A\n",
            "Iteration:   1%|          | 2/250 [00:06<11:27,  2.77s/it]\u001b[A\n",
            "Iteration:   1%|          | 3/250 [00:07<08:50,  2.15s/it]\u001b[A\n",
            "Iteration:   2%|▏         | 4/250 [00:08<07:36,  1.86s/it]\u001b[A\n",
            "Iteration:   2%|▏         | 5/250 [00:10<06:56,  1.70s/it]\u001b[A\n",
            "Iteration:   2%|▏         | 6/250 [00:11<06:31,  1.60s/it]\u001b[A\n",
            "Iteration:   3%|▎         | 7/250 [00:13<06:15,  1.55s/it]\u001b[A\n",
            "Iteration:   3%|▎         | 8/250 [00:14<06:06,  1.52s/it]\u001b[A\n",
            "Iteration:   4%|▎         | 9/250 [00:16<06:01,  1.50s/it]\u001b[A\n",
            "Iteration:   4%|▍         | 10/250 [00:17<05:54,  1.48s/it]\u001b[A\n",
            "Iteration:   4%|▍         | 11/250 [00:18<05:49,  1.46s/it]\u001b[A\n",
            "Iteration:   5%|▍         | 12/250 [00:20<05:46,  1.45s/it]\u001b[A\n",
            "Iteration:   5%|▌         | 13/250 [00:21<05:41,  1.44s/it]\u001b[A\n",
            "Iteration:   6%|▌         | 14/250 [00:23<05:39,  1.44s/it]\u001b[A\n",
            "Iteration:   6%|▌         | 15/250 [00:24<05:37,  1.44s/it]\u001b[A\n",
            "Iteration:   6%|▋         | 16/250 [00:26<05:35,  1.44s/it]\u001b[A\n",
            "Iteration:   7%|▋         | 17/250 [00:27<05:35,  1.44s/it]\u001b[A\n",
            "Iteration:   7%|▋         | 18/250 [00:29<05:36,  1.45s/it]\u001b[A\n",
            "Iteration:   8%|▊         | 19/250 [00:30<05:35,  1.45s/it]\u001b[A\n",
            "Iteration:   8%|▊         | 20/250 [00:31<05:32,  1.45s/it]\u001b[A\n",
            "Iteration:   8%|▊         | 21/250 [00:33<05:31,  1.45s/it]\u001b[A\n",
            "Iteration:   9%|▉         | 22/250 [00:34<05:29,  1.45s/it]\u001b[A\n",
            "Iteration:   9%|▉         | 23/250 [00:36<05:28,  1.45s/it]\u001b[A\n",
            "Iteration:  10%|▉         | 24/250 [00:37<05:26,  1.45s/it]\u001b[A\n",
            "Iteration:  10%|█         | 25/250 [00:39<05:26,  1.45s/it]\u001b[A\n",
            "Iteration:  10%|█         | 26/250 [00:40<05:25,  1.45s/it]\u001b[A\n",
            "Iteration:  11%|█         | 27/250 [00:42<05:26,  1.46s/it]\u001b[A\n",
            "Iteration:  11%|█         | 28/250 [00:43<05:25,  1.47s/it]\u001b[A\n",
            "Iteration:  12%|█▏        | 29/250 [00:45<05:23,  1.46s/it]\u001b[A\n",
            "Iteration:  12%|█▏        | 30/250 [00:46<05:21,  1.46s/it]\u001b[A\n",
            "Iteration:  12%|█▏        | 31/250 [00:47<05:20,  1.46s/it]\u001b[A\n",
            "Iteration:  13%|█▎        | 32/250 [00:49<05:18,  1.46s/it]\u001b[A\n",
            "Iteration:  13%|█▎        | 33/250 [00:50<05:16,  1.46s/it]\u001b[A\n",
            "Iteration:  14%|█▎        | 34/250 [00:52<05:34,  1.55s/it]\u001b[A\n",
            "Iteration:  14%|█▍        | 35/250 [00:54<06:05,  1.70s/it]\u001b[A\n",
            "Iteration:  14%|█▍        | 36/250 [00:56<06:25,  1.80s/it]\u001b[A\n",
            "Iteration:  15%|█▍        | 37/250 [00:58<06:03,  1.71s/it]\u001b[A\n",
            "Iteration:  15%|█▌        | 38/250 [00:59<05:47,  1.64s/it]\u001b[A\n",
            "Iteration:  16%|█▌        | 39/250 [01:01<05:35,  1.59s/it]\u001b[A\n",
            "Iteration:  16%|█▌        | 40/250 [01:02<05:27,  1.56s/it]\u001b[A\n",
            "Iteration:  16%|█▋        | 41/250 [01:04<05:20,  1.53s/it]\u001b[A\n",
            "Iteration:  17%|█▋        | 42/250 [01:05<05:14,  1.51s/it]\u001b[A\n",
            "Iteration:  17%|█▋        | 43/250 [01:07<05:11,  1.50s/it]\u001b[A\n",
            "Iteration:  18%|█▊        | 44/250 [01:08<05:10,  1.51s/it]\u001b[A\n",
            "Iteration:  18%|█▊        | 45/250 [01:10<05:09,  1.51s/it]\u001b[A\n",
            "Iteration:  18%|█▊        | 46/250 [01:11<05:08,  1.51s/it]\u001b[A\n",
            "Iteration:  19%|█▉        | 47/250 [01:13<05:05,  1.51s/it]\u001b[A\n",
            "Iteration:  19%|█▉        | 48/250 [01:14<05:04,  1.51s/it]\u001b[A\n",
            "Iteration:  20%|█▉        | 49/250 [01:16<05:02,  1.50s/it]\u001b[A\n",
            "Iteration:  20%|██        | 50/250 [01:17<04:59,  1.50s/it]\u001b[A\n",
            "Iteration:  20%|██        | 51/250 [01:19<04:58,  1.50s/it]\u001b[A\n",
            "Iteration:  21%|██        | 52/250 [01:20<04:57,  1.50s/it]\u001b[A\n",
            "Iteration:  21%|██        | 53/250 [01:22<04:55,  1.50s/it]\u001b[A\n",
            "Iteration:  22%|██▏       | 54/250 [01:23<04:55,  1.51s/it]\u001b[A\n",
            "Iteration:  22%|██▏       | 55/250 [01:25<04:54,  1.51s/it]\u001b[A\n",
            "Iteration:  22%|██▏       | 56/250 [01:26<04:53,  1.52s/it]\u001b[A\n",
            "Iteration:  23%|██▎       | 57/250 [01:28<04:52,  1.51s/it]\u001b[A\n",
            "Iteration:  23%|██▎       | 58/250 [01:29<04:50,  1.52s/it]\u001b[A\n",
            "Iteration:  24%|██▎       | 59/250 [01:31<04:50,  1.52s/it]\u001b[A\n",
            "Iteration:  24%|██▍       | 60/250 [01:32<04:50,  1.53s/it]\u001b[A\n",
            "Iteration:  24%|██▍       | 61/250 [01:34<04:48,  1.53s/it]\u001b[A\n",
            "Iteration:  25%|██▍       | 62/250 [01:35<04:45,  1.52s/it]\u001b[A\n",
            "Iteration:  25%|██▌       | 63/250 [01:37<04:44,  1.52s/it]\u001b[A\n",
            "Iteration:  26%|██▌       | 64/250 [01:38<04:42,  1.52s/it]\u001b[A\n",
            "Iteration:  26%|██▌       | 65/250 [01:40<04:41,  1.52s/it]\u001b[A\n",
            "Iteration:  26%|██▋       | 66/250 [01:41<04:39,  1.52s/it]\u001b[A\n",
            "Iteration:  27%|██▋       | 67/250 [01:43<04:37,  1.52s/it]\u001b[A\n",
            "Iteration:  27%|██▋       | 68/250 [01:44<04:36,  1.52s/it]\u001b[A\n",
            "Iteration:  28%|██▊       | 69/250 [01:46<04:34,  1.52s/it]\u001b[A\n",
            "Iteration:  28%|██▊       | 70/250 [01:48<04:33,  1.52s/it]\u001b[A\n",
            "Iteration:  28%|██▊       | 71/250 [01:49<04:32,  1.52s/it]\u001b[A\n",
            "Iteration:  29%|██▉       | 72/250 [01:51<04:31,  1.53s/it]\u001b[A\n",
            "Iteration:  29%|██▉       | 73/250 [01:52<04:31,  1.53s/it]\u001b[A\n",
            "Iteration:  30%|██▉       | 74/250 [01:54<04:29,  1.53s/it]\u001b[A\n",
            "Iteration:  30%|███       | 75/250 [01:55<04:29,  1.54s/it]\u001b[A\n",
            "Iteration:  30%|███       | 76/250 [01:57<04:26,  1.53s/it]\u001b[A\n",
            "Iteration:  31%|███       | 77/250 [01:58<04:26,  1.54s/it]\u001b[A\n",
            "Iteration:  31%|███       | 78/250 [02:00<04:24,  1.54s/it]\u001b[A\n",
            "Iteration:  32%|███▏      | 79/250 [02:01<04:22,  1.54s/it]\u001b[A\n",
            "Iteration:  32%|███▏      | 80/250 [02:03<04:21,  1.54s/it]\u001b[A\n",
            "Iteration:  32%|███▏      | 81/250 [02:04<04:20,  1.54s/it]\u001b[A\n",
            "Iteration:  33%|███▎      | 82/250 [02:06<04:19,  1.54s/it]\u001b[A\n",
            "Iteration:  33%|███▎      | 83/250 [02:08<04:17,  1.54s/it]\u001b[A\n",
            "Iteration:  34%|███▎      | 84/250 [02:09<04:15,  1.54s/it]\u001b[A\n",
            "Iteration:  34%|███▍      | 85/250 [02:11<04:14,  1.54s/it]\u001b[A\n",
            "Iteration:  34%|███▍      | 86/250 [02:12<04:14,  1.55s/it]\u001b[A\n",
            "Iteration:  35%|███▍      | 87/250 [02:14<04:12,  1.55s/it]\u001b[A\n",
            "Iteration:  35%|███▌      | 88/250 [02:15<04:10,  1.55s/it]\u001b[A\n",
            "Iteration:  36%|███▌      | 89/250 [02:17<04:08,  1.54s/it]\u001b[A\n",
            "Iteration:  36%|███▌      | 90/250 [02:18<04:07,  1.55s/it]\u001b[A\n",
            "Iteration:  36%|███▋      | 91/250 [02:20<04:06,  1.55s/it]\u001b[A\n",
            "Iteration:  37%|███▋      | 92/250 [02:21<04:05,  1.55s/it]\u001b[A\n",
            "Iteration:  37%|███▋      | 93/250 [02:23<04:03,  1.55s/it]\u001b[A\n",
            "Iteration:  38%|███▊      | 94/250 [02:25<04:01,  1.55s/it]\u001b[A\n",
            "Iteration:  38%|███▊      | 95/250 [02:26<04:00,  1.55s/it]\u001b[A\n",
            "Iteration:  38%|███▊      | 96/250 [02:28<03:59,  1.55s/it]\u001b[A\n",
            "Iteration:  39%|███▉      | 97/250 [02:29<03:57,  1.55s/it]\u001b[A\n",
            "Iteration:  39%|███▉      | 98/250 [02:31<03:55,  1.55s/it]\u001b[A\n",
            "Iteration:  40%|███▉      | 99/250 [02:32<03:54,  1.55s/it]\u001b[A\n",
            "Iteration:  40%|████      | 100/250 [02:34<03:54,  1.57s/it]\u001b[A\n",
            "Iteration:  40%|████      | 101/250 [02:35<03:52,  1.56s/it]\u001b[A\n",
            "Iteration:  41%|████      | 102/250 [02:37<03:50,  1.56s/it]\u001b[A\n",
            "Iteration:  41%|████      | 103/250 [02:39<03:49,  1.56s/it]\u001b[A\n",
            "Iteration:  42%|████▏     | 104/250 [02:40<03:47,  1.56s/it]\u001b[A\n",
            "Iteration:  42%|████▏     | 105/250 [02:42<03:46,  1.56s/it]\u001b[A\n",
            "Iteration:  42%|████▏     | 106/250 [02:43<03:44,  1.56s/it]\u001b[A\n",
            "Iteration:  43%|████▎     | 107/250 [02:45<03:43,  1.56s/it]\u001b[A\n",
            "Iteration:  43%|████▎     | 108/250 [02:46<03:42,  1.57s/it]\u001b[A\n",
            "Iteration:  44%|████▎     | 109/250 [02:48<03:41,  1.57s/it]\u001b[A\n",
            "Iteration:  44%|████▍     | 110/250 [02:50<03:39,  1.57s/it]\u001b[A\n",
            "Iteration:  44%|████▍     | 111/250 [02:51<03:37,  1.57s/it]\u001b[A\n",
            "Iteration:  45%|████▍     | 112/250 [02:53<03:36,  1.57s/it]\u001b[A\n",
            "Iteration:  45%|████▌     | 113/250 [02:54<03:35,  1.57s/it]\u001b[A\n",
            "Iteration:  46%|████▌     | 114/250 [02:56<03:32,  1.56s/it]\u001b[A\n",
            "Iteration:  46%|████▌     | 115/250 [02:57<03:31,  1.57s/it]\u001b[A\n",
            "Iteration:  46%|████▋     | 116/250 [02:59<03:30,  1.57s/it]\u001b[A\n",
            "Iteration:  47%|████▋     | 117/250 [03:01<03:30,  1.58s/it]\u001b[A\n",
            "Iteration:  47%|████▋     | 118/250 [03:02<03:29,  1.58s/it]\u001b[A\n",
            "Iteration:  48%|████▊     | 119/250 [03:04<03:27,  1.58s/it]\u001b[A\n",
            "Iteration:  48%|████▊     | 120/250 [03:05<03:26,  1.59s/it]\u001b[A\n",
            "Iteration:  48%|████▊     | 121/250 [03:07<03:23,  1.58s/it]\u001b[A\n",
            "Iteration:  49%|████▉     | 122/250 [03:08<03:22,  1.58s/it]\u001b[A\n",
            "Iteration:  49%|████▉     | 123/250 [03:10<03:19,  1.57s/it]\u001b[A\n",
            "Iteration:  50%|████▉     | 124/250 [03:12<03:18,  1.58s/it]\u001b[A\n",
            "Iteration:  50%|█████     | 125/250 [03:13<03:17,  1.58s/it]\u001b[A\n",
            "Iteration:  50%|█████     | 126/250 [03:15<03:17,  1.59s/it]\u001b[A\n",
            "Iteration:  51%|█████     | 127/250 [03:16<03:15,  1.59s/it]\u001b[A\n",
            "Iteration:  51%|█████     | 128/250 [03:18<03:14,  1.59s/it]\u001b[A\n",
            "Iteration:  52%|█████▏    | 129/250 [03:20<03:12,  1.59s/it]\u001b[A\n",
            "Iteration:  52%|█████▏    | 130/250 [03:21<03:10,  1.59s/it]\u001b[A\n",
            "Iteration:  52%|█████▏    | 131/250 [03:23<03:09,  1.59s/it]\u001b[A\n",
            "Iteration:  53%|█████▎    | 132/250 [03:24<03:07,  1.59s/it]\u001b[A\n",
            "Iteration:  53%|█████▎    | 133/250 [03:26<03:06,  1.59s/it]\u001b[A\n",
            "Iteration:  54%|█████▎    | 134/250 [03:28<03:05,  1.60s/it]\u001b[A\n",
            "Iteration:  54%|█████▍    | 135/250 [03:29<03:04,  1.61s/it]\u001b[A\n",
            "Iteration:  54%|█████▍    | 136/250 [03:31<03:03,  1.61s/it]\u001b[A\n",
            "Iteration:  55%|█████▍    | 137/250 [03:32<03:02,  1.61s/it]\u001b[A\n",
            "Iteration:  55%|█████▌    | 138/250 [03:34<02:59,  1.61s/it]\u001b[A\n",
            "Iteration:  56%|█████▌    | 139/250 [03:36<02:57,  1.60s/it]\u001b[A\n",
            "Iteration:  56%|█████▌    | 140/250 [03:37<02:56,  1.60s/it]\u001b[A\n",
            "Iteration:  56%|█████▋    | 141/250 [03:39<02:55,  1.61s/it]\u001b[A\n",
            "Iteration:  57%|█████▋    | 142/250 [03:40<02:54,  1.61s/it]\u001b[A\n",
            "Iteration:  57%|█████▋    | 143/250 [03:42<02:53,  1.62s/it]\u001b[A\n",
            "Iteration:  58%|█████▊    | 144/250 [03:44<02:52,  1.63s/it]\u001b[A\n",
            "Iteration:  58%|█████▊    | 145/250 [03:45<02:51,  1.63s/it]\u001b[A\n",
            "Iteration:  58%|█████▊    | 146/250 [03:47<02:49,  1.63s/it]\u001b[A\n",
            "Iteration:  59%|█████▉    | 147/250 [03:49<02:48,  1.63s/it]\u001b[A\n",
            "Iteration:  59%|█████▉    | 148/250 [03:50<02:45,  1.63s/it]\u001b[A\n",
            "Iteration:  60%|█████▉    | 149/250 [03:52<02:43,  1.62s/it]\u001b[A\n",
            "Iteration:  60%|██████    | 150/250 [03:54<02:42,  1.62s/it]\u001b[A\n",
            "Iteration:  60%|██████    | 151/250 [03:55<02:41,  1.63s/it]\u001b[A\n",
            "Iteration:  61%|██████    | 152/250 [03:57<02:39,  1.63s/it]\u001b[A\n",
            "Iteration:  61%|██████    | 153/250 [03:58<02:37,  1.63s/it]\u001b[A\n",
            "Iteration:  62%|██████▏   | 154/250 [04:00<02:36,  1.63s/it]\u001b[A\n",
            "Iteration:  62%|██████▏   | 155/250 [04:02<02:35,  1.63s/it]\u001b[A\n",
            "Iteration:  62%|██████▏   | 156/250 [04:03<02:33,  1.63s/it]\u001b[A\n",
            "Iteration:  63%|██████▎   | 157/250 [04:05<02:31,  1.63s/it]\u001b[A\n",
            "Iteration:  63%|██████▎   | 158/250 [04:07<02:30,  1.63s/it]\u001b[A\n",
            "Iteration:  64%|██████▎   | 159/250 [04:08<02:28,  1.64s/it]\u001b[A\n",
            "Iteration:  64%|██████▍   | 160/250 [04:10<02:27,  1.64s/it]\u001b[A\n",
            "Iteration:  64%|██████▍   | 161/250 [04:12<02:25,  1.64s/it]\u001b[A\n",
            "Iteration:  65%|██████▍   | 162/250 [04:13<02:24,  1.64s/it]\u001b[A\n",
            "Iteration:  65%|██████▌   | 163/250 [04:15<02:22,  1.64s/it]\u001b[A\n",
            "Iteration:  66%|██████▌   | 164/250 [04:16<02:20,  1.64s/it]\u001b[A\n",
            "Iteration:  66%|██████▌   | 165/250 [04:18<02:19,  1.64s/it]\u001b[A\n",
            "Iteration:  66%|██████▋   | 166/250 [04:20<02:18,  1.64s/it]\u001b[A\n",
            "Iteration:  67%|██████▋   | 167/250 [04:21<02:16,  1.64s/it]\u001b[A\n",
            "Iteration:  67%|██████▋   | 168/250 [04:23<02:14,  1.64s/it]\u001b[A\n",
            "Iteration:  68%|██████▊   | 169/250 [04:25<02:13,  1.64s/it]\u001b[A\n",
            "Iteration:  68%|██████▊   | 170/250 [04:26<02:11,  1.64s/it]\u001b[A\n",
            "Iteration:  68%|██████▊   | 171/250 [04:28<02:09,  1.64s/it]\u001b[A\n",
            "Iteration:  69%|██████▉   | 172/250 [04:30<02:07,  1.64s/it]\u001b[A\n",
            "Iteration:  69%|██████▉   | 173/250 [04:31<02:06,  1.64s/it]\u001b[A\n",
            "Iteration:  70%|██████▉   | 174/250 [04:33<02:04,  1.64s/it]\u001b[A\n",
            "Iteration:  70%|███████   | 175/250 [04:34<02:02,  1.63s/it]\u001b[A\n",
            "Iteration:  70%|███████   | 176/250 [04:36<02:01,  1.64s/it]\u001b[A\n",
            "Iteration:  71%|███████   | 177/250 [04:38<02:00,  1.65s/it]\u001b[A\n",
            "Iteration:  71%|███████   | 178/250 [04:39<01:58,  1.65s/it]\u001b[A\n",
            "Iteration:  72%|███████▏  | 179/250 [04:41<01:57,  1.65s/it]\u001b[A\n",
            "Iteration:  72%|███████▏  | 180/250 [04:43<01:55,  1.65s/it]\u001b[A\n",
            "Iteration:  72%|███████▏  | 181/250 [04:44<01:54,  1.65s/it]\u001b[A\n",
            "Iteration:  73%|███████▎  | 182/250 [04:46<01:52,  1.65s/it]\u001b[A\n",
            "Iteration:  73%|███████▎  | 183/250 [04:48<01:50,  1.65s/it]\u001b[A\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "if args.do_train:\n",
        "    global_step, average_loss = trainer.train()\n",
        "    print(\"***** Final Training Results *****\")\n",
        "    print(f\"  Global Step: {global_step}\")\n",
        "    print(f\"  Average Loss: {average_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8RtUFWK6qBH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, int(args.num_train_epochs) + 1)\n",
        "\n",
        "plt.figure(figsize=(18, 4))  # 크기 조절\n",
        "\n",
        "# Loss plot\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(epochs, train_losses, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_losses, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Accuracy plot\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(epochs, train_accuracies, 'r', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracies, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# F1 Score plot 추가\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(val_f1_scores, 'b', label='Validation F1 Score')\n",
        "plt.title('Training and Validation F1 Score')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sjc1wz-axmrM"
      },
      "outputs": [],
      "source": [
        "#trainer.load_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IOeB1M7mPlU"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate(\"test\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ae0d262ed111462eb55a98275be16fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cff43afefc604eeb989af330a214ae95",
              "IPY_MODEL_b9da9433a172417d92d50fe5ab766efd",
              "IPY_MODEL_a2ec15dce12745c4b6fefdcff8280892"
            ],
            "layout": "IPY_MODEL_ac0b462045c34697924a56c0a0feffd5"
          }
        },
        "cff43afefc604eeb989af330a214ae95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_456724b5b4df49a7af483ae1a3f53bb4",
            "placeholder": "​",
            "style": "IPY_MODEL_982e4b34860f495c9bb96d142b52cc48",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "b9da9433a172417d92d50fe5ab766efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c37268b73b041679f42600bdeb2cc1c",
            "max": 255190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9bbb1880feff40ddb80ac8f12d902139",
            "value": 255190
          }
        },
        "a2ec15dce12745c4b6fefdcff8280892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_407035f207154d1db56c77d6fd07cebd",
            "placeholder": "​",
            "style": "IPY_MODEL_266077c939d04b32aa4a7f1c71b37bc2",
            "value": " 255k/255k [00:00&lt;00:00, 3.73MB/s]"
          }
        },
        "ac0b462045c34697924a56c0a0feffd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "456724b5b4df49a7af483ae1a3f53bb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "982e4b34860f495c9bb96d142b52cc48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c37268b73b041679f42600bdeb2cc1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bbb1880feff40ddb80ac8f12d902139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "407035f207154d1db56c77d6fd07cebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "266077c939d04b32aa4a7f1c71b37bc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2edc907a24be43b2ba6d5a0350358dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05719deebece40aea62b7137d525f973",
              "IPY_MODEL_8a4f91b3d9904246905380db3398f412",
              "IPY_MODEL_b0fdbd866ed44ae29e9ccd26c4cfc9c2"
            ],
            "layout": "IPY_MODEL_26cd32f2f1ff42d69cd3e73aff1ee577"
          }
        },
        "05719deebece40aea62b7137d525f973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_266a7bcdde9f4ce4a1e7e75ddee91448",
            "placeholder": "​",
            "style": "IPY_MODEL_f2c68254e69541b280d0c0384d9c2251",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "8a4f91b3d9904246905380db3398f412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b6b841c4c4e4ab1a389f72d00320312",
            "max": 65,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab28e35ca09741639abe71f368c263f7",
            "value": 65
          }
        },
        "b0fdbd866ed44ae29e9ccd26c4cfc9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13b356df94ce48d6a80a5a203103cb71",
            "placeholder": "​",
            "style": "IPY_MODEL_409ae11fbcc24feb8da697e3746f1fff",
            "value": " 65.0/65.0 [00:00&lt;00:00, 3.56kB/s]"
          }
        },
        "26cd32f2f1ff42d69cd3e73aff1ee577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "266a7bcdde9f4ce4a1e7e75ddee91448": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2c68254e69541b280d0c0384d9c2251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b6b841c4c4e4ab1a389f72d00320312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab28e35ca09741639abe71f368c263f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13b356df94ce48d6a80a5a203103cb71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "409ae11fbcc24feb8da697e3746f1fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b935ff23894408abd361a494205d4b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eb20a9ebd1a4645b8762a6087495684",
              "IPY_MODEL_a540df310f0e481cbdef2166f2c11367",
              "IPY_MODEL_e694315724dc4db9b4a2a87438ba9cd3"
            ],
            "layout": "IPY_MODEL_f3a80b0a0a834335be30ede2e9d30852"
          }
        },
        "4eb20a9ebd1a4645b8762a6087495684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cd72da1ee0b4994b7e9ef6c4d8e3e52",
            "placeholder": "​",
            "style": "IPY_MODEL_8d44e3457737463a9e39de645301a248",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "a540df310f0e481cbdef2166f2c11367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_441b7da2e56c4666841cc2a8c6bcb092",
            "max": 487,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ffb02815bcd4cc5ba1da6f09246238c",
            "value": 487
          }
        },
        "e694315724dc4db9b4a2a87438ba9cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_968d158dc9d34fc6aeee820cc3c6dfe7",
            "placeholder": "​",
            "style": "IPY_MODEL_5759a1a57845476daf35486cda13e396",
            "value": " 487/487 [00:00&lt;00:00, 34.5kB/s]"
          }
        },
        "f3a80b0a0a834335be30ede2e9d30852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd72da1ee0b4994b7e9ef6c4d8e3e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d44e3457737463a9e39de645301a248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "441b7da2e56c4666841cc2a8c6bcb092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ffb02815bcd4cc5ba1da6f09246238c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "968d158dc9d34fc6aeee820cc3c6dfe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5759a1a57845476daf35486cda13e396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81f5ad3d801747499074068cbc6853e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_443f78c8af4e4042b388bd3e994feb00",
              "IPY_MODEL_34f2999555c84544909b4869f5fb7a25",
              "IPY_MODEL_74fc649769ba42aba714dc6b60d9f33c"
            ],
            "layout": "IPY_MODEL_b03950292cdd4bdc84127b179952e0ff"
          }
        },
        "443f78c8af4e4042b388bd3e994feb00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c05d22c6c9df40e7b3d78355ca1f4c08",
            "placeholder": "​",
            "style": "IPY_MODEL_e57065daff2c43999b232bf29ab4b965",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "34f2999555c84544909b4869f5fb7a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07540977725248f5bfd9fdfcab80f698",
            "max": 443135628,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8615fbb64f8476f898fc910a54656cb",
            "value": 443135628
          }
        },
        "74fc649769ba42aba714dc6b60d9f33c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28bcc6dccb4f44fdb90fd09335a356ba",
            "placeholder": "​",
            "style": "IPY_MODEL_b65f025d132c41d4b1fb1f434823a33a",
            "value": " 443M/443M [00:10&lt;00:00, 62.7MB/s]"
          }
        },
        "b03950292cdd4bdc84127b179952e0ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c05d22c6c9df40e7b3d78355ca1f4c08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e57065daff2c43999b232bf29ab4b965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07540977725248f5bfd9fdfcab80f698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8615fbb64f8476f898fc910a54656cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28bcc6dccb4f44fdb90fd09335a356ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b65f025d132c41d4b1fb1f434823a33a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}